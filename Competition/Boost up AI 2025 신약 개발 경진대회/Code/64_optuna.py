import numpy as np
import pandas as pd
import os, platform
from tqdm import tqdm
import pickle # ìºì‹œ ì €ì¥/ë¡œë“œë¥¼ ìœ„í•´ pickle ì‚¬ìš©

from rdkit import Chem
from rdkit.Chem import Descriptors, MACCSkeys
from rdkit import DataStructs
from rdkit.Chem import AllChem
from rdkit.Chem.AtomPairs import Pairs
from rdkit.Chem import RDKFingerprint
from mordred import Calculator, descriptors
import torch
from torch.nn import Linear, Module, ReLU, Dropout, BatchNorm1d
from torch.optim.lr_scheduler import ReduceLROnPlateau
from torch_geometric.data import Data
from torch_geometric.loader import DataLoader
from torch_geometric.nn import GATv2Conv, global_mean_pool
from sklearn.model_selection import KFold
from sklearn.feature_selection import SelectFromModel, VarianceThreshold
from sklearn.ensemble import IsolationForest
from sklearn.metrics import mean_squared_error
from scipy.stats import pearsonr
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Lasso

plt.rcParams['font.family'] = 'Malgun Gothic' if platform.system() == 'Windows' else 'AppleGothic'
plt.rcParams['axes.unicode_minus'] = False

class Config:
    seed = 42
    epochs = 200
    patience = 20
    lr_patience = 10
    batch_size = 64
    lr = 0.001
    k_splits = 5

    node_feat_dim = 9 # ì›ì í”¼ì²˜ (ê³ ì •)

    maccs_keys_dim = 167 # MACCS Keys ì°¨ì› (ê³ ì •)
    morgan_dim = 2048 # Morgan Fingerprint ì›ë³¸ ì°¨ì›
    use_topN_morgan = 200 # Morgan FPì—ì„œ ì„ íƒí•  Top N ê°œìˆ˜
    mordred_dim = 60 # Mordred ë””ìŠ¤í¬ë¦½í„°ì—ì„œ ì„ íƒí•  Top N ê°œìˆ˜

    apfp_target_dim = 2048 # APFPë¥¼ íŒ¨ë”©í•  ëª©í‘œ ì°¨ì›
    tfp_initial_dim = 2048 # Topological Fingerprint ì›ë³¸ ì°¨ì›

    rdkit_basic_desc_count = 5 # RDKit ê¸°ë³¸ ë””ìŠ¤í¬ë¦½í„° ê°œìˆ˜

    remove_outliers = True
    outlier_contamination = 0.02

    lasso_alpha = 0.1 # Lasso alpha ê°’

    tuning_apfp_n = 200 # ì´ì „ ìµœì ê°’ìœ¼ë¡œ ê³ ì •
    tuning_tfp_n = 200  # ì´ì „ ìµœì ê°’ìœ¼ë¡œ ê³ ì •

    # âœ¨âœ¨âœ¨ ìƒˆë¡­ê²Œ ì¶”ê°€ëœ GNN í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ê°’ë“¤ âœ¨âœ¨âœ¨
    tuning_hidden_dims = [64, 128, 256] # GATv2 hidden_dim í›„ë³´êµ°
    tuning_num_heads = [4, 6, 8]       # GATv2 num_heads í›„ë³´êµ°
    tuning_dropout_rates = [0.3, 0.4, 0.5] # Dropout rate í›„ë³´êµ°
    tuning_lrs = [0.001, 0.0005] # Learning rate í›„ë³´êµ°

    mordred_cache_path = './_save/mordred_combined_cache.csv'
    morgan_cache_path = './_save/morgan_fps_cache.npy'
    maccs_cache_path = './_save/maccs_keys_cache.npy'
    apfp_cache_path = './_save/apfp_cache.npy'
    tfp_cache_path = './_save/tfp_cache.npy'
    rdkit_desc_cache_path = './_save/rdkit_desc_cache.npy'

# ì‹œë“œ ê³ ì •
np.random.seed(Config.seed)
torch.manual_seed(Config.seed)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
os.makedirs('./_save', exist_ok=True)

def atom_features(atom):
    return np.array([
        atom.GetSymbol() == 'C', atom.GetSymbol() == 'N', atom.GetSymbol() == 'O',
        atom.GetSymbol() == 'S', atom.GetSymbol() == 'F', atom.GetSymbol() == 'Cl',
        atom.GetSymbol() == 'Br', atom.GetSymbol() == 'I', atom.GetDegree(),
    ], dtype=np.float32)

calc = Calculator(descriptors, ignore_3D=True)

def get_morgan_fingerprint(mol, dim=Config.morgan_dim):
    if mol is None:
        return np.zeros(dim, dtype=np.float32)
    return np.array(AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=dim), dtype=np.float32)

def get_maccs_keys(mol):
    if mol is None:
        return np.zeros(Config.maccs_keys_dim, dtype=np.float32)
    return np.array(MACCSkeys.GenMACCSKeys(mol), dtype=np.float32)

def get_atom_pair_fingerprint(mol):
    if mol is None:
        return np.array([], dtype=np.float32) # Return empty array if mol is None
    return np.array(Pairs.GetAtomPairFingerprintAsBitVect(mol), dtype=np.float32)

def get_topological_fingerprint(mol, dim=Config.tfp_initial_dim):
    if mol is None:
        return np.zeros(dim, dtype=np.float32)
    return np.array(RDKFingerprint(mol, fpSize=dim), dtype=np.float32)

def get_rdkit_descriptors(mol):
    if mol is None:
        return np.array([0.0] * Config.rdkit_basic_desc_count, dtype=np.float32)

    logp = Descriptors.MolLogP(mol)
    tpsa = Descriptors.TPSA(mol)
    mw = Descriptors.MolWt(mol)
    hbd = Descriptors.NumHDonors(mol)
    hba = Descriptors.NumHAcceptors(mol)
    return np.array([logp, tpsa, mw, hbd, hba], dtype=np.float32)

def standardize_fingerprints(fp_list, target_dim, dtype=np.float32):
    if not fp_list:
        return np.empty((0, target_dim), dtype=dtype)
    standardized_fps = []
    for fp in fp_list:
        # â­ï¸ ë³€ê²½ëœ ë¶€ë¶„: ë¹ˆ ë°°ì—´ë„ ì²˜ë¦¬ ê°€ëŠ¥í•˜ë„ë¡ í•¨
        if fp.size == 0:
            standardized_fps.append(np.zeros(target_dim, dtype=dtype))
        elif fp.shape[0] < target_dim:
            padded_fp = np.pad(fp, (0, target_dim - fp.shape[0]), 'constant')
            standardized_fps.append(padded_fp)
        else:
            standardized_fps.append(fp[:target_dim])
    return np.array(standardized_fps, dtype=dtype)

def mol_to_graph_data(mol, global_feat, y=None):
    if mol is None: # â­ï¸ ì¶”ê°€ëœ ë¶€ë¶„: molì´ Noneì´ë©´ ì²˜ë¦¬í•˜ì§€ ì•Šê³  None ë°˜í™˜
        return None

    x = []
    edge_index = []

    for atom in mol.GetAtoms():
        x.append(atom_features(atom))
    x = torch.tensor(np.array(x), dtype=torch.float)

    for bond in mol.GetBonds():
        start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()
        edge_index.append([start, end])
        edge_index.append([end, start])

    if len(edge_index) == 0:
        # ë‹¨ì¼ ì›ì ë˜ëŠ” ì—°ê²°ì´ ì—†ëŠ” ê²½ìš°ë¥¼ ìœ„í•œ ì²˜ë¦¬
        if x.size(0) > 0: # ì›ìê°€ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ìê¸° ë£¨í”„ ì¶”ê°€
            edge_index = torch.tensor([[0,0]], dtype=torch.long)
        else: # ì›ìê°€ ì „í˜€ ì—†ëŠ” ê²½ìš° (ê±°ì˜ ë°œìƒí•˜ì§€ ì•Šì§€ë§Œ ì•ˆì „ì„ ìœ„í•´)
            return None # ê·¸ë˜í”„ë¥¼ ë§Œë“¤ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ None ë°˜í™˜
    else:
        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()

    global_feat_tensor = torch.tensor(global_feat, dtype=torch.float).view(1, -1)

    if y is not None:
        return Data(x=x, edge_index=edge_index, global_feat=global_feat_tensor, y=torch.tensor(y, dtype=torch.float).view(-1))
    else:
        return Data(x=x, edge_index=edge_index, global_feat=global_feat_tensor)

class GATv2WithGlobal(Module):
    def __init__(self, node_feat_dim, global_feat_dim, hidden_dim, out_dim, num_heads, dropout_rate):
        super(GATv2WithGlobal, self).__init__()
        self.node_feat_dim = node_feat_dim
        self.global_feat_dim = global_feat_dim
        self.hidden_dim = hidden_dim

        self.conv1 = GATv2Conv(node_feat_dim, hidden_dim, heads=num_heads, dropout=dropout_rate, add_self_loops=True)
        self.bn1 = BatchNorm1d(hidden_dim * num_heads)
        self.conv2 = GATv2Conv(hidden_dim * num_heads, hidden_dim, heads=num_heads, dropout=dropout_rate, add_self_loops=True)
        self.bn2 = BatchNorm1d(hidden_dim * num_heads)
        self.conv3 = GATv2Conv(hidden_dim * num_heads, hidden_dim, heads=num_heads, dropout=dropout_rate, add_self_loops=True)
        self.bn3 = BatchNorm1d(hidden_dim * num_heads)

        self.pooled_dim = hidden_dim * num_heads
        self.combined_dim = self.pooled_dim + self.global_feat_dim

        self.fc1 = Linear(self.combined_dim, hidden_dim)
        self.relu = ReLU()
        self.dropout = Dropout(dropout_rate)
        self.fc2 = Linear(hidden_dim, out_dim)

    def forward(self, data):
        x, edge_index, batch, global_feat = data.x, data.edge_index, data.batch, data.global_feat

        x = self.conv1(x, edge_index)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.dropout(x)

        x = self.conv2(x, edge_index)
        x = self.bn2(x)
        x = self.relu(x)
        x = self.dropout(x)

        x = self.conv3(x, edge_index)
        x = self.bn3(x)
        x = self.relu(x)
        x = self.dropout(x)

        x = global_mean_pool(x, batch)

        combined_features = torch.cat([x, global_feat.squeeze(1)], dim=1)

        x = self.fc1(combined_features)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        return x.view(-1)

if __name__ == '__main__':
    print("ë°ì´í„° ë¡œë“œ ë° ì´ˆê¸° ì¤€ë¹„ ì‹œì‘...")
    train_df_original = pd.read_csv('./_data/dacon/new/train.csv').drop_duplicates('Canonical_Smiles').reset_index(drop=True)
    test_df_original = pd.read_csv('./_data/dacon/new/test.csv')
    submit_df_original = pd.read_csv('./_data/dacon/new/sample_submission.csv')

    # â­ï¸ ìˆ˜ì •ëœ ë¶€ë¶„: combined_smiles_rawì—ì„œ ì¤‘ë³µ ì œê±°
    combined_smiles_raw = train_df_original['Canonical_Smiles'].tolist() + \
                            test_df_original['Canonical_Smiles'].tolist()
                            
    print(f"ì´ {len(combined_smiles_raw)}ê°œì˜ SMILESë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.")

    print("Mordred Descriptors ì²˜ë¦¬ ì¤‘ (ìºì‹± í™œìš©)...")
    mordred_combined_df = None
    recalculate_mordred = False

    if os.path.exists(Config.mordred_cache_path):
        try:
            mordred_combined_df = pd.read_csv(Config.mordred_cache_path)
            if mordred_combined_df.empty or mordred_combined_df.shape[0] != len(combined_smiles_raw):
                print("ê²½ê³ : ë¡œë“œëœ Mordred ìºì‹œ íŒŒì¼ì´ ë¹„ì–´ìˆê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•Šê±°ë‚˜ ë°ì´í„° ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•Šì•„ ë‹¤ì‹œ ê³„ì‚°í•©ë‹ˆë‹¤.")
                recalculate_mordred = True
            else:
                print(f"ë¡œë“œëœ Mordred ë°ì´í„° ì°¨ì›: {mordred_combined_df.shape}")
        except pd.errors.EmptyDataError:
            print("ê²½ê³ : Mordred ìºì‹œ íŒŒì¼ì´ ë¹„ì–´ìˆì–´ ë‹¤ì‹œ ê³„ì‚°í•©ë‹ˆë‹¤.")
            recalculate_mordred = True
        except Exception as e:
            print(f"ê²½ê³ : Mordred ìºì‹œ íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({e}). ë‹¤ì‹œ ê³„ì‚°í•©ë‹ˆë‹¤.")
            recalculate_mordred = True
    else:
        print("Mordred Descriptors ìºì‹œ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šì•„ ìƒˆë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.")
        recalculate_mordred = True

    if recalculate_mordred:
        print("Mordred Descriptors ê³„ì‚° ì¤‘ (ì „ì²´ ë°ì´í„°)...")
        # â­ï¸ ìˆ˜ì •ëœ ë¶€ë¶„: combined_mols_raw ëŒ€ì‹  combined_smiles_rawë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ê³  ê° SMILESë§ˆë‹¤ mol ìƒì„±
        combined_mols_raw = [] # Mordred ê³„ì‚°ì„ ìœ„í•´ ëª° ê°ì²´ ë¦¬ìŠ¤íŠ¸ ìƒì„±
        for smiles in tqdm(combined_smiles_raw, desc="SMILES -> Mol ë³€í™˜ (Mordred)"):
            mol = Chem.MolFromSmiles(smiles)
            combined_mols_raw.append(mol)

        try:
            mordred_df_temp = calc.pandas(combined_mols_raw, n_jobs=-1, quiet=True)
            
            mordred_combined_df = mordred_df_temp.select_dtypes(include=np.number).fillna(0)
            
            mordred_combined_df = mordred_combined_df.loc[:, mordred_combined_df.apply(pd.Series.nunique) != 1]

            print(f"\nMordred ê³„ì‚° ì„±ê³µ. ì´ ë””ìŠ¤í¬ë¦½í„° ì°¨ì›: {mordred_combined_df.shape[1]}")
        except Exception as e:
            print(f"ERROR: Mordred ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {type(e).__name__} - {e}")
            print("Mordred ê³„ì‚°ì— ì‹¤íŒ¨í•˜ì—¬ ë¹ˆ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            mordred_combined_df = pd.DataFrame(np.zeros((len(combined_smiles_raw), 0)), columns=[])
        
        mordred_combined_df.to_csv(Config.mordred_cache_path, index=False)
        print("Mordred Descriptors ìºì‹œ íŒŒì¼ ì €ì¥ ì™„ë£Œ.")

    print("\nëª¨ë“  Fingerprint ë° RDKit Descriptors ì²˜ë¦¬ ì¤‘ (ìºì‹± í™œìš©)...")

    calculated_morgan_fps = []
    calculated_maccs_keys = []
    calculated_apfp = []
    calculated_tfp = []
    calculated_rdkit_descriptors = []

    fp_desc_configs = [
        {"name": "Morgan FP", "path": Config.morgan_cache_path, "gen_func": get_morgan_fingerprint, "target_list": calculated_morgan_fps, "dim_param": Config.morgan_dim},
        {"name": "MACCS Keys", "path": Config.maccs_cache_path, "gen_func": get_maccs_keys, "target_list": calculated_maccs_keys, "dim_param": None},
        {"name": "APFP", "path": Config.apfp_cache_path, "gen_func": get_atom_pair_fingerprint, "target_list": calculated_apfp, "dim_param": None},
        {"name": "TFP", "path": Config.tfp_cache_path, "gen_func": get_topological_fingerprint, "target_list": calculated_tfp, "dim_param": Config.tfp_initial_dim},
        {"name": "RDKit Descriptors", "path": Config.rdkit_desc_cache_path, "gen_func": get_rdkit_descriptors, "target_list": calculated_rdkit_descriptors, "dim_param": None}
    ]

    for fp_desc_info in fp_desc_configs:
        name = fp_desc_info["name"]
        path = fp_desc_info["path"]
        gen_func = fp_desc_info["gen_func"]
        target_list = fp_desc_info["target_list"]
        dim_param = fp_desc_info["dim_param"]

        recalculate_fp_desc = False

        if os.path.exists(path):
            try:
                loaded_data = np.load(path)
                if loaded_data.shape[0] != len(combined_smiles_raw):
                    print(f"ê²½ê³ : ë¡œë“œëœ {name} ìºì‹œ íŒŒì¼ì˜ ë°ì´í„° ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•Šì•„ ë‹¤ì‹œ ê³„ì‚°í•©ë‹ˆë‹¤.")
                    recalculate_fp_desc = True
                else:
                    target_list.extend(list(loaded_data))
                    print(f"ë¡œë“œëœ {name} ë°ì´í„° ì°¨ì›: {loaded_data.shape}")
            except Exception as e:
                print(f"ê²½ê³ : {name} ìºì‹œ íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({e}). ë‹¤ì‹œ ê³„ì‚°í•©ë‹ˆë‹¤.")
                recalculate_fp_desc = True
        else:
            print(f"{name} ìºì‹œ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šì•„ ìƒˆë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.")
            recalculate_fp_desc = True

        if recalculate_fp_desc:
            print(f"{name} ê³„ì‚° ì¤‘ (ì „ì²´ ë°ì´í„°)...")
            temp_fp_list = []
            for i, smiles in tqdm(enumerate(combined_smiles_raw), total=len(combined_smiles_raw), desc=f"Calculating {name}"):
                mol = Chem.MolFromSmiles(smiles) # â­ï¸ ìˆ˜ì •ëœ ë¶€ë¶„: ì—¬ê¸°ì„œ mol ê°ì²´ ìƒì„±
                if dim_param is not None:
                    temp_fp_list.append(gen_func(mol, dim=dim_param))
                else:
                    temp_fp_list.append(gen_func(mol)) # â­ï¸ ìˆ˜ì •ëœ ë¶€ë¶„: get_*_fingerprint í•¨ìˆ˜ë“¤ì´ Noneì„ ì²˜ë¦¬í•˜ë„ë¡ í•¨

            if name == "APFP":
                processed_fps = standardize_fingerprints(temp_fp_list, Config.apfp_target_dim)
                target_list.extend(list(processed_fps))
                np.save(path, processed_fps)
            else:
                arr = np.array(temp_fp_list)
                target_list.extend(list(arr))
                np.save(path, arr)
            print(f"{name} ìºì‹œ íŒŒì¼ ì €ì¥ ì™„ë£Œ. ì°¨ì›: {target_list[0].shape if target_list else 'N/A'}")
        
    all_morgan_fps_raw = np.array(calculated_morgan_fps)
    all_maccs_keys_raw = np.array(calculated_maccs_keys)
    all_apfp_raw = np.array(calculated_apfp)
    all_tfp_raw = np.array(calculated_tfp)
    all_rdkit_descriptors_raw = np.array(calculated_rdkit_descriptors)

    print("ëª¨ë“  Fingerprint ë° RDKit Descriptors ê³„ì‚° ë˜ëŠ” ë¡œë“œ ì™„ë£Œ.")

    # ----------------------------------------------------------------------------------------------------
    # âœ¨âœ¨âœ¨ GNN í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ë£¨í”„ ì‹œì‘ âœ¨âœ¨âœ¨
    # ----------------------------------------------------------------------------------------------------
    gnn_tuning_results = {} # GNN í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ê²°ê³¼ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
    best_gnn_overall_score = -float('inf')
    best_gnn_params = {}
    final_best_test_predictions = None

    for current_hidden_dim in Config.tuning_hidden_dims:
        for current_num_heads in Config.tuning_num_heads:
            for current_dropout_rate in Config.tuning_dropout_rates:
                for current_lr in Config.tuning_lrs:
                    print(f"\n===== GNN íŠœë‹ ì¡°í•©: hidden_dim={current_hidden_dim}, num_heads={current_num_heads}, dropout_rate={current_dropout_rate}, lr={current_lr} =====")
                    
                    # íŠœë‹ ì¤‘ì¸ GNN í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ Configì— ì„ì‹œë¡œ ì—…ë°ì´íŠ¸
                    Config.hidden_dim = current_hidden_dim
                    Config.num_heads = current_num_heads
                    Config.dropout_rate = current_dropout_rate
                    Config.lr = current_lr

                    # í”¼ì²˜ ì „ì²˜ë¦¬ (ì´ ë¶€ë¶„ì€ GNN í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ê³¼ ì§ì ‘ì ì¸ ê´€ë ¨ì´ ì—†ìœ¼ë¯€ë¡œ,
                    # ì´ì „ ìµœì  APFP N=200, TFP N=200ì„ ì‚¬ìš©í•˜ì—¬ ê³ ì •)
                    # ë§Œì•½ APFP/TFPë„ í•¨ê»˜ íŠœë‹í•˜ë ¤ë©´ ì´ ë¶€ë¶„ì„ íŠœë‹ ë£¨í”„ ì•ˆì— ë„£ì–´ì•¼ í•©ë‹ˆë‹¤.

                    train_df = train_df_original.copy()
                    test_df = test_df_original.copy()
                    
                    current_all_morgan_fps = all_morgan_fps_raw.copy()
                    current_all_apfp = all_apfp_raw.copy()
                    current_all_tfp = all_tfp_raw.copy()
                    current_all_rdkit_descriptors = all_rdkit_descriptors_raw.copy()

                    # Mordred íŠ¹ì„± ì „ì²˜ë¦¬
                    mordred_processed = None
                    if mordred_combined_df.shape[1] == 0:
                        mordred_processed = np.empty((mordred_combined_df.shape[0], 0))
                    else:
                        vt = VarianceThreshold(threshold=0.0)
                        mordred_vt = vt.fit_transform(mordred_combined_df)
                        mordred_vt_cols = mordred_combined_df.columns[vt.get_support()]

                        scaler = StandardScaler()
                        mordred_scaled = scaler.fit_transform(mordred_vt)

                        corr_threshold = 0.95
                        mordred_df_temp = pd.DataFrame(mordred_scaled, columns=mordred_vt_cols)

                        if mordred_df_temp.shape[1] > 1:
                            corr_matrix = mordred_df_temp.corr().abs()
                            upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))
                            to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > corr_threshold)]
                        else:
                            to_drop = []

                        if to_drop:
                            mordred_filtered_corr_df = mordred_df_temp.drop(columns=to_drop)
                            mordred_filtered_corr = mordred_filtered_corr_df.values
                        else:
                            mordred_filtered_corr_df = mordred_df_temp
                            mordred_filtered_corr = mordred_scaled

                        if mordred_filtered_corr.shape[1] > 0:
                            lasso_model_mordred = Lasso(alpha=Config.lasso_alpha, random_state=Config.seed)
                            lasso_model_mordred.fit(mordred_filtered_corr[:len(train_df)], train_df['Inhibition'].values)
                            selector_mordred = SelectFromModel(lasso_model_mordred, max_features=Config.mordred_dim, prefit=True, threshold=-np.inf)
                            mordred_processed = selector_mordred.transform(mordred_filtered_corr)
                        else:
                            mordred_processed = np.empty((mordred_filtered_corr.shape[0], 0))
                    print(f"Mordred ì²˜ë¦¬ëœ ì°¨ì›: {mordred_processed.shape}")

                    # Morgan Fingerprint í”¼ì²˜ ì„ íƒ (Config.use_topN_morgan ì‚¬ìš©)
                    morgan_fps_processed = None
                    if current_all_morgan_fps.shape[1] > 0:
                        lasso_model_morgan = Lasso(alpha=Config.lasso_alpha, random_state=Config.seed)
                        lasso_model_morgan.fit(current_all_morgan_fps[:len(train_df)], train_df['Inhibition'].values)
                        selector_morgan = SelectFromModel(lasso_model_morgan, max_features=Config.use_topN_morgan, prefit=True, threshold=-np.inf)
                        morgan_fps_processed = selector_morgan.transform(current_all_morgan_fps)
                    else:
                        morgan_fps_processed = np.empty((current_all_morgan_fps.shape[0], 0))
                    print(f"Morgan FP ì²˜ë¦¬ëœ ì°¨ì›: {morgan_fps_processed.shape}")

                    # APFP í”¼ì²˜ ì„ íƒ (Config.tuning_apfp_n ì‚¬ìš©)
                    apfp_processed = None
                    if current_all_apfp.shape[1] > 0:
                        lasso_model_apfp = Lasso(alpha=Config.lasso_alpha, random_state=Config.seed)
                        lasso_model_apfp.fit(current_all_apfp[:len(train_df)], train_df['Inhibition'].values)
                        selector_apfp = SelectFromModel(lasso_model_apfp, max_features=Config.tuning_apfp_n, prefit=True, threshold=-np.inf)
                        apfp_processed = selector_apfp.transform(current_all_apfp)
                    else:
                        apfp_processed = np.empty((current_all_apfp.shape[0], 0))
                    print(f"APFP ì²˜ë¦¬ëœ ì°¨ì›: {apfp_processed.shape}")

                    # TFP í”¼ì²˜ ì„ íƒ (Config.tuning_tfp_n ì‚¬ìš©)
                    tfp_processed = None
                    if current_all_tfp.shape[1] > 0:
                        lasso_model_tfp = Lasso(alpha=Config.lasso_alpha, random_state=Config.seed)
                        lasso_model_tfp.fit(current_all_tfp[:len(train_df)], train_df['Inhibition'].values)
                        selector_tfp = SelectFromModel(lasso_model_tfp, max_features=Config.tuning_tfp_n, prefit=True, threshold=-np.inf)
                        tfp_processed = selector_tfp.transform(current_all_tfp)
                    else:
                        tfp_processed = np.empty((current_all_tfp.shape[0], 0))
                    print(f"TFP ì²˜ë¦¬ëœ ì°¨ì›: {tfp_processed.shape}")

                    # RDKit ê¸°ë³¸ ë””ìŠ¤í¬ë¦½í„° ì „ì²˜ë¦¬
                    rdkit_desc_processed = None
                    if current_all_rdkit_descriptors.shape[1] > 0:
                        scaler_rdkit = StandardScaler()
                        rdkit_scaled = scaler_rdkit.fit_transform(current_all_rdkit_descriptors)

                        lasso_model_rdkit = Lasso(alpha=Config.lasso_alpha, random_state=Config.seed)
                        lasso_model_rdkit.fit(rdkit_scaled[:len(train_df)], train_df['Inhibition'].values)
                        selector_rdkit = SelectFromModel(lasso_model_rdkit, prefit=True, threshold=-np.inf)
                        rdkit_desc_processed = selector_rdkit.transform(rdkit_scaled)
                    else:
                        rdkit_desc_processed = np.empty((current_all_rdkit_descriptors.shape[0], 0))
                    print(f"RDKit ë””ìŠ¤í¬ë¦½í„° ì²˜ë¦¬ëœ ì°¨ì›: {rdkit_desc_processed.shape}")

                    # ëª¨ë“  ì „ì²˜ë¦¬ëœ í”¼ì²˜ ê²°í•©
                    global_features_combined = np.hstack([
                        mordred_processed,
                        morgan_fps_processed,
                        all_maccs_keys_raw, # MACCS KeysëŠ” Top N ì„ íƒ ì—†ì´ ëª¨ë‘ ì‚¬ìš©
                        apfp_processed,
                        tfp_processed,
                        rdkit_desc_processed
                    ])
                    print(f"ëª¨ë“  Global Features ê²°í•©ëœ ì°¨ì›: {global_features_combined.shape}")

                    X_train_global = global_features_combined[:len(train_df_original)] # original train_df_original ê¸¸ì´ë¡œ ë¶„ë¦¬
                    y_train_original = train_df_original['Inhibition'].values # original train_df_originalì˜ yê°’

                    # ì•„ì›ƒë¼ì´ì–´ ì œê±° ë¡œì§
                    if Config.remove_outliers:
                        print("í›ˆë ¨ ë°ì´í„°ì—ì„œ ì•„ì›ƒë¼ì´ì–´ ì œê±° ì¤‘...")
                        iso_forest = IsolationForest(contamination=Config.outlier_contamination, random_state=Config.seed, n_jobs=-1)
                        outlier_preds = iso_forest.fit_predict(X_train_global)
                        
                        train_df_filtered = train_df_original[outlier_preds == 1].reset_index(drop=True)
                        X_train_global_filtered = X_train_global[outlier_preds == 1]
                        y_train_filtered = y_train_original[outlier_preds == 1]
                        print(f"ì•„ì›ƒë¼ì´ì–´ ì œê±° í›„ í›ˆë ¨ ë°ì´í„° ìˆ˜: {len(train_df_filtered)} (ì œê±°ëœ ìˆ˜: {len(train_df_original) - len(train_df_filtered)})")
                    else:
                        train_df_filtered = train_df_original
                        X_train_global_filtered = X_train_global
                        y_train_filtered = y_train_original
                    
                    X_test_global = global_features_combined[len(train_df_original):] # test_df_original ê¸¸ì´ë§Œí¼ë§Œ ì¶”ì¶œ
                    
                    kf = KFold(n_splits=Config.k_splits, shuffle=True, random_state=Config.seed)
                    fold_results = []
                    test_preds_folds_current_gnn_params = [] # í˜„ì¬ GNN íŒŒë¼ë¯¸í„° ì¡°í•©ì— ëŒ€í•œ test_preds_folds

                    for fold, (train_idx, val_idx) in enumerate(kf.split(train_df_filtered)):
                        print(f"\n--- Fold {fold+1}/{Config.k_splits} ---")
                        
                        fold_train_df = train_df_filtered.iloc[train_idx]
                        fold_val_df = train_df_filtered.iloc[val_idx]
                        
                        fold_X_train_global = X_train_global_filtered[train_idx]
                        fold_y_train = y_train_filtered[train_idx]
                        fold_X_val_global = X_train_global_filtered[val_idx]
                        fold_y_val = y_train_filtered[val_idx]

                        # Graph ë°ì´í„° ìƒì„±
                        train_data_list = []
                        for i in tqdm(range(len(fold_train_df)), desc="Train Graph Data"):
                            smiles = fold_train_df.iloc[i]['Canonical_Smiles']
                            mol = Chem.MolFromSmiles(smiles)
                            data = mol_to_graph_data(mol, fold_X_train_global[i], fold_y_train[i])
                            if data is not None:
                                train_data_list.append(data)
                        
                        val_data_list = []
                        for i in tqdm(range(len(fold_val_df)), desc="Validation Graph Data"):
                            smiles = fold_val_df.iloc[i]['Canonical_Smiles']
                            mol = Chem.MolFromSmiles(smiles)
                            data = mol_to_graph_data(mol, fold_X_val_global[i], fold_y_val[i])
                            if data is not None:
                                val_data_list.append(data)

                        train_loader = DataLoader(train_data_list, batch_size=Config.batch_size, shuffle=True)
                        val_loader = DataLoader(val_data_list, batch_size=Config.batch_size, shuffle=False)

                        # ëª¨ë¸ ì´ˆê¸°í™” (í˜„ì¬ íŠœë‹ ì¤‘ì¸ GNN í•˜ì´í¼íŒŒë¼ë¯¸í„° ì‚¬ìš©)
                        model = GATv2WithGlobal(
                            node_feat_dim=Config.node_feat_dim,
                            global_feat_dim=global_features_combined.shape[1], # ê²°í•©ëœ ê¸€ë¡œë²Œ í”¼ì²˜ ì°¨ì›
                            hidden_dim=Config.hidden_dim, # âœ¨ íŠœë‹ ë³€ìˆ˜ ì ìš©
                            out_dim=1,
                            num_heads=Config.num_heads, # âœ¨ íŠœë‹ ë³€ìˆ˜ ì ìš©
                            dropout_rate=Config.dropout_rate # âœ¨ íŠœë‹ ë³€ìˆ˜ ì ìš©
                        ).to(device)

                        optimizer = torch.optim.Adam(model.parameters(), lr=Config.lr) # âœ¨ íŠœë‹ ë³€ìˆ˜ ì ìš©
                        criterion = torch.nn.MSELoss()
                        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.7, patience=Config.lr_patience, verbose=True)

                        best_val_rmse = float('inf')
                        epochs_no_improve = 0
                        
                        for epoch in range(1, Config.epochs + 1):
                            model.train()
                            total_loss = 0
                            for data in train_loader:
                                data = data.to(device)
                                optimizer.zero_grad()
                                out = model(data)
                                loss = criterion(out, data.y)
                                loss.backward()
                                optimizer.step()
                                total_loss += loss.item() * data.num_graphs

                            avg_train_loss = total_loss / len(train_loader.dataset)
                            
                            # Validation
                            model.eval()
                            val_preds = []
                            val_targets = []
                            with torch.no_grad():
                                for data in val_loader:
                                    data = data.to(device)
                                    out = model(data)
                                    val_preds.extend(out.cpu().numpy())
                                    val_targets.extend(data.y.cpu().numpy())
                            
                            val_rmse = np.sqrt(mean_squared_error(val_targets, val_preds))
                            val_pcc = pearsonr(val_targets, val_preds)[0] if len(val_targets) > 1 else 0.0

                            scheduler.step(val_rmse)

                            # Early stopping
                            if val_rmse < best_val_rmse:
                                best_val_rmse = val_rmse
                                epochs_no_improve = 0
                                # Save best model for this fold and current GNN params
                                torch.save(model.state_dict(), f'best_model_fold_{fold}_h{current_hidden_dim}_nh{current_num_heads}_dp{current_dropout_rate}_lr{current_lr}.pth')
                            else:
                                epochs_no_improve += 1
                                if epochs_no_improve == Config.patience:
                                    print(f"Early stopping at epoch {epoch}")
                                    break
                            
                            if epoch % 10 == 0 or epoch == 1 or epoch == Config.epochs:
                                print(f"Epoch {epoch}/{Config.epochs}, Train Loss: {avg_train_loss:.4f}, Val RMSE: {val_rmse:.4f}, Val PCC: {val_pcc:.4f}")

                        # Load best model for evaluation and test prediction
                        model.load_state_dict(torch.load(f'best_model_fold_{fold}_h{current_hidden_dim}_nh{current_num_heads}_dp{current_dropout_rate}_lr{current_lr}.pth'))
                        model.eval()

                        final_val_preds = []
                        final_val_targets = []
                        with torch.no_grad():
                            for data in val_loader:
                                data = data.to(device)
                                out = model(data)
                                final_val_preds.extend(out.cpu().numpy())
                                final_val_targets.extend(data.y.cpu().numpy())
                        
                        final_val_rmse = np.sqrt(mean_squared_error(final_val_targets, final_val_preds))
                        final_val_pcc = pearsonr(final_val_targets, final_val_preds)[0] if len(final_val_targets) > 1 else 0.0
                        print(f"Fold {fold+1} Best Val RMSE: {final_val_rmse:.4f}, Best Val PCC: {final_val_pcc:.4f}")
                        fold_results.append({'rmse': final_val_rmse, 'pcc': final_val_pcc})

                        # Test prediction for this fold
                        test_data_list = []
                        # test_df_originalì„ ì‚¬ìš©í•˜ì—¬ mol_to_graph_dataë¥¼ í˜¸ì¶œ (ì›ë˜ test set)
                        for i in tqdm(range(len(test_df_original)), desc="Test Graph Data"):
                            smiles = test_df_original.iloc[i]['Canonical_Smiles']
                            mol = Chem.MolFromSmiles(smiles)
                            # X_test_globalì€ ì´ë¯¸ test_df_originalì— í•´ë‹¹í•˜ëŠ” ë¶€ë¶„ì…ë‹ˆë‹¤.
                            data = mol_to_graph_data(mol, X_test_global[i])
                            if data is not None:
                                test_data_list.append(data)
                        
                        test_loader = DataLoader(test_data_list, batch_size=Config.batch_size, shuffle=False)
                        
                        fold_test_preds = []
                        with torch.no_grad():
                            for data in test_loader:
                                data = data.to(device)
                                out = model(data)
                                fold_test_preds.extend(out.cpu().numpy())
                        test_preds_folds_current_gnn_params.append(np.array(fold_test_preds))

                    # ----------------------------------------------------------------------------------------------------
                    # ğŸ”§ GNN ì¡°í•©ë³„ ê²°ê³¼ ì§‘ê³„ ë° ì €ì¥
                    # ----------------------------------------------------------------------------------------------------
                    avg_rmse = np.mean([res['rmse'] for res in fold_results])
                    avg_pcc = np.mean([res['pcc'] for res in fold_results])
                    print(f"\nAverage RMSE across folds for current GNN params: {avg_rmse:.4f}")
                    print(f"Average PCC across folds for current GNN params: {avg_pcc:.4f}")
                    
                    gnn_param_key = f"H{current_hidden_dim}_NH{current_num_heads}_DP{current_dropout_rate}_LR{current_lr}"
                    gnn_tuning_results[gnn_param_key] = {'rmse': avg_rmse, 'pcc': avg_pcc}

                    # í˜„ì¬ ì¡°í•©ì˜ ì ìˆ˜ ê³„ì‚° (PCCë¥¼ ìµœëŒ€í™”)
                    current_overall_score = avg_pcc
                    if current_overall_score > best_gnn_overall_score:
                        best_gnn_overall_score = current_overall_score
                        best_gnn_params = {
                            'hidden_dim': current_hidden_dim,
                            'num_heads': current_num_heads,
                            'dropout_rate': current_dropout_rate,
                            'lr': current_lr
                        }
                        # ìµœì ì˜ GNN ì¡°í•©ì¼ ë•Œë§Œ ìµœì¢… ì˜ˆì¸¡ê°’ì„ ì €ì¥
                        final_best_test_predictions = np.mean(test_preds_folds_current_gnn_params, axis=0)
                        print(f"ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥ GNN ì¡°í•© ë°œê²¬: {gnn_param_key} (PCC: {best_gnn_overall_score:.4f})")
    
    # ----------------------------------------------------------------------------------------------------
    # ğŸ”§ ìµœì¢… ê²°ê³¼ ë° ì œì¶œ íŒŒì¼ ìƒì„±
    # ----------------------------------------------------------------------------------------------------
    print("\n--- GNN í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì™„ë£Œ ---")
    print("\níŠœë‹ ê²°ê³¼:")
    for combo, metrics in gnn_tuning_results.items():
        print(f"GNN Params {combo}: RMSE={metrics['rmse']:.4f}, PCC={metrics['pcc']:.4f}")
    
    print(f"\nìµœì ì˜ GNN ì¡°í•©: {best_gnn_params} (ìµœê³  PCC: {best_gnn_overall_score:.4f})")

    # ìµœì¢… ì œì¶œ íŒŒì¼ ìƒì„± (ìµœì ì˜ GNN ì¡°í•©ìœ¼ë¡œ ê³„ì‚°ëœ ì˜ˆì¸¡ê°’ ì‚¬ìš©)
    if final_best_test_predictions is not None:
        submit_df = submit_df_original.copy()
        submit_df['Inhibition'] = final_best_test_predictions
        
        # âœ¨âœ¨âœ¨ ì œì¶œ íŒŒì¼ ì¸ì½”ë”© ì˜¤ë¥˜ í•´ê²°: encoding='utf-8' ëª…ì‹œ âœ¨âœ¨âœ¨
        submission_filename = f"submission_APFP_N{Config.tuning_apfp_n}_TFP_N{Config.tuning_tfp_n}_GNN_H{best_gnn_params['hidden_dim']}_NH{best_gnn_params['num_heads']}_DP{best_gnn_params['dropout_rate']}_LR{best_gnn_params['lr']}.csv"
        submit_df.to_csv(submission_filename, index=False, encoding='utf-8')
        print(f"\nSubmission íŒŒì¼ '{submission_filename}'ì´(ê°€) UTF-8ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("ìµœì  GNN ì¡°í•©ì˜ ì˜ˆì¸¡ê°’ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ì œì¶œ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")