import os
import pandas as pd
import numpy as np
from rdkit import Chem
from rdkit.Chem import Descriptors
from sklearn.model_selection import KFold
from sklearn.preprocessing import RobustScaler
from sklearn.decomposition import PCA
from sklearn.metrics import mean_squared_error
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping

# âœ… ì €ì¥ ê²½ë¡œ
save_dir = './_save/dnn_pca_models/'
os.makedirs(save_dir, exist_ok=True)

# âœ… ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
path = './_data/dacon/new/'
train_raw = pd.read_csv(path + 'train.csv')
test_raw = pd.read_csv(path + 'test.csv')
submit = pd.read_csv(path + 'sample_submission.csv')

# âœ… RDKit í”¼ì²˜ ì¶”ì¶œ
def featurize(smiles):
    mol = Chem.MolFromSmiles(smiles)
    if mol is None:
        return None
    return {
        'MolWt': Descriptors.MolWt(mol),
        'MolLogP': Descriptors.MolLogP(mol),
        'TPSA': Descriptors.TPSA(mol),
        'NumHDonors': Descriptors.NumHDonors(mol),
        'NumHAcceptors': Descriptors.NumHAcceptors(mol),
        'NumRotatableBonds': Descriptors.NumRotatableBonds(mol),
        'FractionCSP3': Descriptors.FractionCSP3(mol),
        'NumRings': Descriptors.RingCount(mol),
        'HeavyAtomCount': Descriptors.HeavyAtomCount(mol),
        'ExactMolWt': Descriptors.ExactMolWt(mol),
        'MolWt_TPSA': Descriptors.MolWt(mol) * Descriptors.TPSA(mol),
        'Donor/Acceptor': Descriptors.NumHDonors(mol) / (Descriptors.NumHAcceptors(mol) + 1),
        'RotBond2': Descriptors.NumRotatableBonds(mol) ** 2
    }

import matplotlib.pyplot as plt
import seaborn as sns

# âœ… í”¼ì²˜ ìƒì„±
train_features = train_raw['Canonical_Smiles'].apply(featurize)
test_features = test_raw['Canonical_Smiles'].apply(featurize)
train_df = pd.DataFrame(train_features.tolist())
test_df = pd.DataFrame(test_features.tolist())
train_df['Inhibition'] = train_raw['Inhibition']

# RDKit í”¼ì²˜ë§Œ ì„ íƒ (íƒ€ê²Ÿ ì œì™¸)
feature_corr_df = train_df.drop(columns=['Inhibition'])

# ìƒê´€ê³„ìˆ˜ ê³„ì‚°
corr = feature_corr_df.corr()

# íˆíŠ¸ë§µ ì‹œê°í™”
plt.figure(figsize=(12, 10))
sns.heatmap(corr, annot=True, fmt=".2f", cmap='coolwarm', square=True,
            cbar_kws={"shrink": 0.8}, linewidths=0.5, linecolor='gray')
plt.title('RDKit Descriptor Correlation Heatmap', fontsize=16)
plt.xticks(rotation=45, ha='right')
plt.yticks(rotation=0)
plt.tight_layout()
plt.show()

exit()

# âœ… ë¶ˆí•„ìš” ì»¬ëŸ¼ ì œê±°
drop_cols = ['ExactMolWt', 'MolWt_TPSA', 'RotBond2']
train_df.drop(columns=drop_cols, inplace=True)
test_df.drop(columns=drop_cols, inplace=True)

# âœ… log1p ë³€í™˜
log_cols = ['MolWt', 'TPSA', 'HeavyAtomCount']
for col in log_cols:
    train_df[col] = np.log1p(train_df[col])
    test_df[col] = np.log1p(test_df[col])

# âœ… ì´ì§„í™”
bin_cols = ['NumHDonors', 'NumHAcceptors', 'NumRotatableBonds']
for col in bin_cols:
    train_df[f'{col}_bin'] = (train_df[col] > 0).astype(int)
    test_df[f'{col}_bin'] = (test_df[col] > 0).astype(int)

# âœ… ìŠ¤ì¼€ì¼ë§
X = train_df.drop(columns=['Inhibition'])
y = train_df['Inhibition']
X_test = test_df.copy()

scaler = RobustScaler()
X_scaled = scaler.fit_transform(X)
X_test_scaled = scaler.transform(X_test)

# print(X_scaled.shape)
# exit()

# âœ… PCA ì ìš©
n_pca_components = 13
pca = PCA(n_components=n_pca_components)
X_scaled_pca = pca.fit_transform(X_scaled)
X_test_scaled_pca = pca.transform(X_test_scaled)

# âœ… ëª¨ë¸ ì •ì˜
def build_model(input_dim):
    model = Sequential([
        Dense(128, activation='relu', input_dim=input_dim),
        BatchNormalization(),
        Dropout(0.2),
        Dense(64, activation='relu'),
        BatchNormalization(),
        Dropout(0.2),
        Dense(32, activation='relu'),
        BatchNormalization(),
        Dropout(0.1),
        Dense(1)
    ])
    model.compile(loss='huber', optimizer='adam')
    return model

# âœ… KFold í•™ìŠµ
n_splits = 3
seed = 222
kfold = KFold(n_splits=n_splits, shuffle=True, random_state=seed)
test_preds = np.zeros(len(X_test_scaled_pca))
valid_scores = []

for fold, (train_idx, val_idx) in enumerate(kfold.split(X_scaled_pca)):
    print(f"\nğŸ“‚ Fold {fold+1}")
    X_train, X_val = X_scaled_pca[train_idx], X_scaled_pca[val_idx]
    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

    model = build_model(X_train.shape[1])
    es = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True, verbose=1)

    model.fit(X_train, y_train,
              validation_data=(X_val, y_val),
              epochs=300, batch_size=32,
              callbacks=[es], verbose=1)

    # ëª¨ë¸ ì €ì¥
    model_path = os.path.join(save_dir, f'dnn_pca_fold{fold+1}.h5')
    model.save(model_path)
    print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_path}")

    val_pred = model.predict(X_val).flatten()
    mse = mean_squared_error(y_val, val_pred)
    rmse = np.sqrt(mse)
    valid_scores.append(rmse)
    print(f"âœ… Fold {fold+1} RMSE: {rmse:.5f}")

    test_preds += model.predict(X_test_scaled_pca).flatten() / n_splits

# âœ… ì œì¶œ ì €ì¥
print(f"\nğŸ¯ í‰ê·  RMSE (PCA {n_pca_components}D): {np.mean(valid_scores):.5f}")
submit['Inhibition'] = test_preds
submit.to_csv(path + f'dnn_submission_pca{n_pca_components}.csv', index=False)
print(f"ğŸ“„ ì €ì¥ ì™„ë£Œ: dnn_submission_pca{n_pca_components}.csv")

# í‰ê·  RMSE (PCA 13D): 25.14013
