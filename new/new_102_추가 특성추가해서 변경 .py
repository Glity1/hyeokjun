# ğŸ”§ ëª©ì : GNN (GATv2) ê¸°ë°˜ ë¶„ì ë¬¼ì„± ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸ (ì´ìƒì¹˜ ì²˜ë¦¬ ë° K-Fold í¬í•¨)
#         - RDKit ê¸°ë³¸ ë””ìŠ¤í¬ë¦½í„°, APFP, TFP ì¶”ê°€
#         - ëª¨ë“  íŠ¹ì„± ì„ íƒì— Lasso (L1 ê·œì œ) ê¸°ë°˜ ì ìš©
#         - APFP ë° TFP ê³„ì‚° ê²°ê³¼ ìºì‹± ì¶”ê°€

import numpy as np
import pandas as pd
import os, platform
from tqdm import tqdm
import pickle # ìºì‹œ ì €ì¥/ë¡œë“œë¥¼ ìœ„í•´ pickle ì‚¬ìš© (numpy ë°°ì—´ ì €ì¥ì— ìš©ì´)

from rdkit import Chem
from rdkit.Chem import Descriptors, MACCSkeys
from rdkit import DataStructs
from rdkit.Chem import AllChem # AllChemì—ì„œ GetMorganFingerprintAsBitVect ë“±ì„ ì‚¬ìš©
from rdkit.Chem.AtomPairs import Pairs # GetAtomPairFingerprintAsBitVectë¥¼ ìœ„í•´ ì„í¬íŠ¸
from rdkit.Chem import RDKFingerprint # TFP ì„í¬íŠ¸
from mordred import Calculator, descriptors
import torch
from torch.nn import Linear, Module, ReLU, Dropout, BatchNorm1d
from torch.optim.lr_scheduler import ReduceLROnPlateau
from torch_geometric.data import Data
from torch_geometric.loader import DataLoader
from torch_geometric.nn import GATv2Conv, global_mean_pool
from sklearn.model_selection import KFold
from sklearn.feature_selection import SelectFromModel, VarianceThreshold
from sklearn.ensemble import RandomForestRegressor, IsolationForest
from sklearn.metrics import mean_squared_error
from scipy.stats import pearsonr
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.linear_model import Lasso

# í°íŠ¸ ì„¤ì • (ìš´ì˜ì²´ì œì— ë”°ë¼)
plt.rcParams['font.family'] = 'Malgun Gothic' if platform.system() == 'Windows' else 'AppleGothic'
plt.rcParams['axes.unicode_minus'] = False

# âœ… ì„¤ì • í´ë˜ìŠ¤
class Config:
    seed = 42
    epochs = 200
    patience = 20
    lr_patience = 10
    batch_size = 64
    lr = 0.001
    k_splits = 5

    # Feature Dimensions (ì—¬ê¸°ì— ê¸°ë³¸ê°’ì„ ì„¤ì •í•˜ê³  ë£¨í”„ì—ì„œ ì—…ë°ì´íŠ¸)
    node_feat_dim = 9 # ì›ì í”¼ì²˜ (ê³ ì •)

    maccs_keys_dim = 167 # MACCS Keys ì°¨ì› (ê³ ì •)
    morgan_dim = 2048 # Morgan Fingerprint ì›ë³¸ ì°¨ì› (ìƒì„± ì‹œ)
    use_topN_morgan = 200 # Morgan Fingerprintì—ì„œ ì„ íƒí•  Top N ê°œìˆ˜ (ìµœì‹  ê²°ê³¼ì— ë”°ë¼ 200ìœ¼ë¡œ ê³ ì •)
    mordred_dim = 60 # Mordred ë””ìŠ¤í¬ë¦½í„°ì—ì„œ ì„ íƒí•  Top N ê°œìˆ˜ (ìµœì‹  ê²°ê³¼ì— ë”°ë¼ 60ìœ¼ë¡œ ê³ ì •)

    # ìƒˆë¡œ ì¶”ê°€ë  Fingerprint ë° RDKit Descriptors ì°¨ì› ì •ì˜
    # APFPëŠ” GetAtomPairFingerprintAsBitVectê°€ nBitsë¥¼ ë°›ì§€ ì•Šìœ¼ë¯€ë¡œ, ì´ ê°’ì€ í˜„ì¬ ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    # ê·¸ëŸ¬ë‚˜ í†µì¼ëœ ì°¨ì›ìœ¼ë¡œ íŒ¨ë”©í•˜ê¸° ìœ„í•œ ëª©í‘œ ì°¨ì›ìœ¼ë¡œ Morgan FPì˜ ì°¨ì›ì„ ì¬í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    apfp_target_dim = 2048 # APFPë¥¼ íŒ¨ë”©í•  ëª©í‘œ ì°¨ì› (Morgan FPì™€ ë™ì¼í•˜ê²Œ ì„¤ì •)
    tfp_initial_dim = 2048 # Topological Fingerprint ì›ë³¸ ì°¨ì› (RDKFingerprintì˜ fpSizeì— ì‚¬ìš©)

    # RDKit ê¸°ë³¸ ë””ìŠ¤í¬ë¦½í„° ê°œìˆ˜ (LogP, TPSA, MolWt, NumHDonors, NumHAcceptors)
    rdkit_basic_desc_count = 5

    # ì´ìƒì¹˜ ì²˜ë¦¬ ì„¤ì •
    remove_outliers = True
    outlier_contamination = 0.02

    # Lasso alpha ê°’ (L1 ê·œì œ ê°•ë„)
    lasso_alpha = 0.1 # <-- ìµœì  íŠœë‹ ê²°ê³¼ì— ë”°ë¼ 0.1ë¡œ ê³ ì •

    # ìºì‹œ íŒŒì¼ ê²½ë¡œ (ì¶”ê°€)
    mordred_cache_path = './_save/mordred_combined_cache.csv'
    morgan_cache_path = './_save/morgan_fps_cache.npy'
    maccs_cache_path = './_save/maccs_keys_cache.npy'
    apfp_cache_path = './_save/apfp_cache.npy'
    tfp_cache_path = './_save/tfp_cache.npy'
    rdkit_desc_cache_path = './_save/rdkit_desc_cache.npy'


# ì‹œë“œ ê³ ì •
np.random.seed(Config.seed)
torch.manual_seed(Config.seed)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
os.makedirs('./_save', exist_ok=True)

# ----------------------------------------------------------------------------------------------------
# ğŸ”§ 1. í”¼ì²˜ ì¶”ì¶œ ë° ê·¸ë˜í”„ ìƒì„± í•¨ìˆ˜ ì •ì˜
# ----------------------------------------------------------------------------------------------------
def atom_features(atom):
    """ì›ì íŠ¹ì„± ë²¡í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    return np.array([
        atom.GetSymbol() == 'C',
        atom.GetSymbol() == 'N',
        atom.GetSymbol() == 'O',
        atom.GetSymbol() == 'S',
        atom.GetSymbol() == 'F',
        atom.GetSymbol() == 'Cl',
        atom.GetSymbol() == 'Br',
        atom.GetSymbol() == 'I',
        atom.GetDegree(),
    ], dtype=np.float32)

# Mordred ê³„ì‚°ê¸° ì´ˆê¸°í™”
calc = Calculator(descriptors, ignore_3D=True)

def get_morgan_fingerprint(mol, dim=Config.morgan_dim):
    """Morgan Fingerprintë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    return np.array(AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=dim), dtype=np.float32)

def get_maccs_keys(mol):
    """MACCS Keysë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    return np.array(MACCSkeys.GenMACCSKeys(mol), dtype=np.float32)

def get_atom_pair_fingerprint(mol):
    """Atom Pair Fingerprintë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    return np.array(Pairs.GetAtomPairFingerprintAsBitVect(mol), dtype=np.float32)

def get_topological_fingerprint(mol, dim=Config.tfp_initial_dim):
    """Topological Fingerprint (RDKitFP)ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    return np.array(RDKFingerprint(mol, fpSize=dim), dtype=np.float32)

def get_rdkit_descriptors(mol):
    """RDKit ê¸°ë³¸ ë””ìŠ¤í¬ë¦½í„° (LogP, TPSA, MolWt, NumHDonors, NumHAcceptors)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    if mol is None:
        return np.array([0.0] * Config.rdkit_basic_desc_count, dtype=np.float32)

    logp = Descriptors.MolLogP(mol)
    tpsa = Descriptors.TPSA(mol)
    mw = Descriptors.MolWt(mol)
    hbd = Descriptors.NumHDonors(mol)
    hba = Descriptors.NumHAcceptors(mol)

    return np.array([logp, tpsa, mw, hbd, hba], dtype=np.float32)

# APFPì²˜ëŸ¼ ê°€ë³€ ê¸¸ì´ ë°°ì—´ì„ ê³ ì • ê¸¸ì´ë¡œ í†µì¼í•˜ëŠ” í•¨ìˆ˜
def standardize_fingerprints(fp_list, target_dim, dtype=np.float32):
    """
    ê°€ë³€ ê¸¸ì´ í•‘ê±°í”„ë¦°íŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ íŠ¹ì • ì°¨ì›ìœ¼ë¡œ íŒ¨ë”©í•˜ê±°ë‚˜ ìë¦…ë‹ˆë‹¤.
    ì£¼ë¡œ APFPì™€ ê°™ì´ ê¸¸ì´ê°€ ê°€ë³€ì ì¸ í•‘ê±°í”„ë¦°íŠ¸ë¥¼ ê³ ì • ê¸¸ì´ë¡œ ë§Œë“¤ ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    if not fp_list:
        return np.empty((0, target_dim), dtype=dtype)

    standardized_fps = []
    for fp in fp_list:
        if fp.size == 0:
            standardized_fps.append(np.zeros(target_dim, dtype=dtype))
        elif fp.shape[0] < target_dim:
            padded_fp = np.pad(fp, (0, target_dim - fp.shape[0]), 'constant')
            standardized_fps.append(padded_fp)
        else: # fp.shape[0] >= target_dim
            standardized_fps.append(fp[:target_dim]) # ëª©í‘œ ì°¨ì›ë³´ë‹¤ ê¸¸ë©´ ìë¥´ê¸°
    return np.array(standardized_fps, dtype=dtype)


def mol_to_graph_data(mol, global_feat, y=None):
    """RDKit Mol ê°ì²´ì™€ ê¸€ë¡œë²Œ í”¼ì²˜ë¥¼ PyTorch Geometric Data ê°ì²´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    x = []
    edge_index = []

    for atom in mol.GetAtoms():
        x.append(atom_features(atom))
    x = torch.tensor(np.array(x), dtype=torch.float)

    for bond in mol.GetBonds():
        start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()
        edge_index.append([start, end])
        edge_index.append([end, start])

    if len(edge_index) == 0:
        edge_index = torch.tensor([[0,0]], dtype=torch.long) # ë¹ˆ ë¶„ì ê·¸ë˜í”„ ì²˜ë¦¬
    else:
        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()

    global_feat_tensor = torch.tensor(global_feat, dtype=torch.float).view(1, -1)

    if y is not None:
        return Data(x=x, edge_index=edge_index, global_feat=global_feat_tensor, y=torch.tensor(y, dtype=torch.float).view(-1))
    else:
        return Data(x=x, edge_index=edge_index, global_feat=global_feat_tensor)

# ----------------------------------------------------------------------------------------------------
# ğŸ”§ 2. GNN ëª¨ë¸ ì •ì˜
# ----------------------------------------------------------------------------------------------------
class GATv2WithGlobal(Module):
    def __init__(self, node_feat_dim, global_feat_dim, hidden_dim, out_dim, num_heads, dropout_rate):
        super(GATv2WithGlobal, self).__init__()
        self.node_feat_dim = node_feat_dim
        self.global_feat_dim = global_feat_dim
        self.hidden_dim = hidden_dim

        self.conv1 = GATv2Conv(node_feat_dim, hidden_dim, heads=num_heads, dropout=dropout_rate, add_self_loops=True)
        self.bn1 = BatchNorm1d(hidden_dim * num_heads)
        self.conv2 = GATv2Conv(hidden_dim * num_heads, hidden_dim, heads=num_heads, dropout=dropout_rate, add_self_loops=True)
        self.bn2 = BatchNorm1d(hidden_dim * num_heads)
        self.conv3 = GATv2Conv(hidden_dim * num_heads, hidden_dim, heads=num_heads, dropout=dropout_rate, add_self_loops=True)
        self.bn3 = BatchNorm1d(hidden_dim * num_heads)

        self.pooled_dim = hidden_dim * num_heads
        self.combined_dim = self.pooled_dim + self.global_feat_dim

        self.fc1 = Linear(self.combined_dim, hidden_dim)
        self.relu = ReLU()
        self.dropout = Dropout(dropout_rate)
        self.fc2 = Linear(hidden_dim, out_dim)

    def forward(self, data):
        x, edge_index, batch, global_feat = data.x, data.edge_index, data.batch, data.global_feat

        x = self.conv1(x, edge_index)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.dropout(x)

        x = self.conv2(x, edge_index)
        x = self.bn2(x)
        x = self.relu(x)
        x = self.dropout(x)

        x = self.conv3(x, edge_index)
        x = self.bn3(x)
        x = self.relu(x)
        x = self.dropout(x)

        x = global_mean_pool(x, batch)

        combined_features = torch.cat([x, global_feat.squeeze(1)], dim=1)

        x = self.fc1(combined_features)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc2(x)
        return x.view(-1)

# ====================================================================================
# âœ… ë©”ì¸ ì‹¤í–‰ ë¸”ë¡
# ====================================================================================
if __name__ == '__main__':
    # ----------------------------------------------------------------------------------------------------
    # ğŸ”§ 0. í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • (ê³ ì •ëœ ê°’ ì‚¬ìš©)
    # ----------------------------------------------------------------------------------------------------
    # í˜„ì¬ Morgan FP ì°¨ì› 200, Mordred 60, Lasso Alpha 0.1ë¡œ ê³ ì •
    # ë‹¤ìŒ íŠœë‹ì€ GNN hidden_dim, num_heads, ë ˆì´ì–´ ìˆ˜, dropout_rate, outlier_contamination ë“±
    
    # í”¼ì²˜ ì¤‘ìš”ë„ ë° ìƒê´€ê´€ê³„ ì‹œê°í™”ë¥¼ ìœ„í•´ í•„ìš”í•œ ë³€ìˆ˜ë“¤ ì´ˆê¸°í™” (ìµœì  alphaì— ëŒ€í•œ ê²ƒë§Œ ì €ì¥)
    best_morgan_selected_features_df = None
    best_lasso_model_morgan = None
    best_morgan_feature_columns = None
    
    best_mordred_feature_columns = None
    best_lasso_model_mordred = None
    best_mordred_all_filtered_columns = pd.Index([]) # Pylance ê²½ê³  í•´ê²° ìœ„í•´ ë³€ìˆ˜ëª… í†µì¼ (ì‚¬ìš© ì—¬ë¶€ì™€ ë¬´ê´€í•˜ê²Œ ì •ì˜)


    # ----------------------------------------------------------------------------------------------------
    # ğŸ”§ 3. ë°ì´í„° ë¡œë“œ ë° ì´ˆê¸° ì¤€ë¹„ (í•œ ë²ˆë§Œ ì‹¤í–‰)
    # ----------------------------------------------------------------------------------------------------
    print("ë°ì´í„° ë¡œë“œ ë° ì´ˆê¸° ì¤€ë¹„ ì‹œì‘...")
    train_df_original = pd.read_csv('./_data/dacon/new/train.csv').drop_duplicates('Canonical_Smiles').reset_index(drop=True)
    test_df_original = pd.read_csv('./_data/dacon/new/test.csv')
    submit_df_original = pd.read_csv('./_data/dacon/new/sample_submission.csv')

    combined_smiles_raw = train_df_original['Canonical_Smiles'].tolist() + \
                          test_df_original['Canonical_Smiles'].tolist() + \
                          test_df_original['Canonical_Smiles'].tolist() # ì œì¶œìš© ë°ì´í„°ë„ í¬í•¨

    print(f"ì´ {len(combined_smiles_raw)}ê°œì˜ SMILESë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.")

    # ----------------------------------------------------------------------------------------------------
    # ğŸ”§ 4. Mordred ë””ìŠ¤í¬ë¦½í„° ê³„ì‚° (ìºì‹± í¬í•¨, í•œ ë²ˆë§Œ ì‹¤í–‰)
    # ----------------------------------------------------------------------------------------------------
    print("Mordred Descriptors ì²˜ë¦¬ ì¤‘ (ìºì‹± í™œìš©)...")
    mordred_combined_df = None
    recalculate_mordred = False

    if os.path.exists(Config.mordred_cache_path):
        try:
            mordred_combined_df = pd.read_csv(Config.mordred_cache_path)
            if mordred_combined_df.empty or mordred_combined_df.shape[0] != len(combined_smiles_raw):
                print("ê²½ê³ : ë¡œë“œëœ Mordred ìºì‹œ íŒŒì¼ì´ ë¹„ì–´ìˆê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•Šê±°ë‚˜ ë°ì´í„° ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•Šì•„ ë‹¤ì‹œ ê³„ì‚°í•©ë‹ˆë‹¤.")
                recalculate_mordred = True
            else:
                print(f"ë¡œë“œëœ Mordred ë°ì´í„° ì°¨ì›: {mordred_combined_df.shape}")
        except pd.errors.EmptyDataError:
            print("ê²½ê³ : Mordred ìºì‹œ íŒŒì¼ì´ ë¹„ì–´ìˆì–´ ë‹¤ì‹œ ê³„ì‚°í•©ë‹ˆë‹¤.")
            recalculate_mordred = True
        except Exception as e:
            print(f"ê²½ê³ : Mordred ìºì‹œ íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({e}). ë‹¤ì‹œ ê³„ì‚°í•©ë‹ˆë‹¤.")
            recalculate_mordred = True
    else:
        print("Mordred Descriptors ìºì‹œ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šì•„ ìƒˆë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.")
        recalculate_mordred = True

    if recalculate_mordred:
        print("Mordred Descriptors ê³„ì‚° ì¤‘ (ì „ì²´ ë°ì´í„°)...")
        combined_mols_raw = []
        for smiles in tqdm(combined_smiles_raw, desc="SMILES -> Mol ë³€í™˜"):
            mol = Chem.MolFromSmiles(smiles)
            combined_mols_raw.append(mol)
        try:
            mordred_combined_df_raw = calc.pandas(combined_mols_raw)
            mordred_combined_df = mordred_combined_df_raw.select_dtypes(include=np.number).fillna(0)
            
            num_mordred_features = mordred_combined_df.shape[1]
            print(f"\n--- Mordred ê³„ì‚° ê²°ê³¼ ìš”ì•½ ---")
            print(f"Mordred ê³„ì‚° ì„±ê³µ. ì´ ë””ìŠ¤í¬ë¦½í„° ì°¨ì›: {num_mordred_features}")
            print(f"---------------------------------------------------\n")
        except Exception as e:
            print(f"ERROR: Mordred ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {type(e).__name__} - {e}")
            print("Mordred ê³„ì‚°ì— ì‹¤íŒ¨í•˜ì—¬ ë¹ˆ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            num_mordred_features = 0
            mordred_combined_df = pd.DataFrame(np.zeros((len(combined_smiles_raw), 0)), columns=[])
        mordred_combined_df.to_csv(Config.mordred_cache_path, index=False)
        print("Mordred Descriptors ìºì‹œ íŒŒì¼ ì €ì¥ ì™„ë£Œ.")


    # ----------------------------------------------------------------------------------------------------
    # ğŸ”§ 5. ëª¨ë“  Fingerprint ë° RDKit Descriptors ê³„ì‚° (ìºì‹± í¬í•¨)
    # ----------------------------------------------------------------------------------------------------
    print("\nëª¨ë“  Fingerprint ë° RDKit Descriptors ì²˜ë¦¬ ì¤‘ (ìºì‹± í™œìš©)...")

    # ëª¨ë“  FP/Descë¥¼ ì €ì¥í•  ì»¨í…Œì´ë„ˆ ì´ˆê¸°í™” (ë¦¬ìŠ¤íŠ¸)
    calculated_morgan_fps = []
    calculated_maccs_keys = []
    calculated_apfp = []
    calculated_tfp = []
    calculated_rdkit_descriptors = []

    # ê° í•‘ê±°í”„ë¦°íŠ¸/ë””ìŠ¤í¬ë¦½í„°ë³„ ìºì‹± ë¡œì§
    fp_desc_configs = [
        {"name": "Morgan FP", "path": Config.morgan_cache_path, "gen_func": get_morgan_fingerprint, "target_list": calculated_morgan_fps, "dim_param": Config.morgan_dim},
        {"name": "MACCS Keys", "path": Config.maccs_cache_path, "gen_func": get_maccs_keys, "target_list": calculated_maccs_keys, "dim_param": None}, # MACCSëŠ” ê³ ì • dim
        {"name": "APFP", "path": Config.apfp_cache_path, "gen_func": get_atom_pair_fingerprint, "target_list": calculated_apfp, "dim_param": None}, # APFPëŠ” nBits ì—†ìŒ
        {"name": "TFP", "path": Config.tfp_cache_path, "gen_func": get_topological_fingerprint, "target_list": calculated_tfp, "dim_param": Config.tfp_initial_dim},
        {"name": "RDKit Descriptors", "path": Config.rdkit_desc_cache_path, "gen_func": get_rdkit_descriptors, "target_list": calculated_rdkit_descriptors, "dim_param": None} # RDKit descëŠ” ê³ ì • ê°œìˆ˜
    ]

    # ì„ì‹œ ëª° ê°ì²´ ë¦¬ìŠ¤íŠ¸ (ê³„ì‚° í•„ìš” ì‹œì—ë§Œ ìƒì„±)
    combined_mols_for_fp_desc = [Chem.MolFromSmiles(s) for s in combined_smiles_raw]

    for fp_desc_info in fp_desc_configs:
        name = fp_desc_info["name"]
        path = fp_desc_info["path"]
        gen_func = fp_desc_info["gen_func"]
        target_list = fp_desc_info["target_list"]
        dim_param = fp_desc_info["dim_param"]

        recalculate_fp_desc = False

        if os.path.exists(path):
            try:
                loaded_data = np.load(path)
                if loaded_data.shape[0] != len(combined_smiles_raw):
                    print(f"ê²½ê³ : ë¡œë“œëœ {name} ìºì‹œ íŒŒì¼ì˜ ë°ì´í„° ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•Šì•„ ë‹¤ì‹œ ê³„ì‚°í•©ë‹ˆë‹¤.")
                    recalculate_fp_desc = True
                else:
                    target_list.extend(list(loaded_data)) # ë¡œë“œëœ ë°ì´í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                    print(f"ë¡œë“œëœ {name} ë°ì´í„° ì°¨ì›: {loaded_data.shape}")
            except Exception as e:
                print(f"ê²½ê³ : {name} ìºì‹œ íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({e}). ë‹¤ì‹œ ê³„ì‚°í•©ë‹ˆë‹¤.")
                recalculate_fp_desc = True
        else:
            print(f"{name} ìºì‹œ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šì•„ ìƒˆë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.")
            recalculate_fp_desc = True

        if recalculate_fp_desc:
            print(f"{name} ê³„ì‚° ì¤‘ (ì „ì²´ ë°ì´í„°)...")
            temp_fp_list = []
            for i, mol in tqdm(enumerate(combined_mols_for_fp_desc), total=len(combined_mols_for_fp_desc), desc=f"Calculating {name}"):
                if mol:
                    # dim_paramì´ ìˆìœ¼ë©´ ì „ë‹¬, ì—†ìœ¼ë©´ gen_funcë§Œ í˜¸ì¶œ
                    if dim_param is not None:
                        temp_fp_list.append(gen_func(mol, dim=dim_param))
                    else:
                        temp_fp_list.append(gen_func(mol))
                else:
                    # ìœ íš¨í•˜ì§€ ì•Šì€ SMILESì— ëŒ€í•œ ì²˜ë¦¬
                    if "Morgan" in name:
                        temp_fp_list.append(np.zeros(Config.morgan_dim, dtype=np.float32))
                    elif "MACCS" in name:
                        temp_fp_list.append(np.zeros(Config.maccs_keys_dim, dtype=np.float32))
                    elif "APFP" in name:
                        temp_fp_list.append(np.zeros(Config.apfp_target_dim, dtype=np.float32)) # APFPëŠ” í†µì¼ëœ ì°¨ì›ìœ¼ë¡œ 0 ì±„ì›€
                    elif "TFP" in name:
                        temp_fp_list.append(np.zeros(Config.tfp_initial_dim, dtype=np.float32))
                    elif "RDKit" in name:
                        temp_fp_list.append(np.zeros(Config.rdkit_basic_desc_count, dtype=np.float32))
                    else: # ì•ˆì „ì¥ì¹˜
                        temp_fp_list.append(np.array([], dtype=np.float32))
            
            # APFPëŠ” íŠ¹ë³„íˆ ì°¨ì› í†µì¼ í•¨ìˆ˜ë¥¼ ê±°ì³ì•¼ í•¨
            if name == "APFP":
                processed_fps = standardize_fingerprints(temp_fp_list, Config.apfp_target_dim)
                target_list.extend(list(processed_fps)) # extendëŠ” ë¦¬ìŠ¤íŠ¸ì— ì›ì†Œë¥¼ ì¶”ê°€
                np.save(path, processed_fps)
            else:
                arr = np.array(temp_fp_list)
                target_list.extend(list(arr))
                np.save(path, arr)
            print(f"{name} ìºì‹œ íŒŒì¼ ì €ì¥ ì™„ë£Œ. ì°¨ì›: {target_list[0].shape if target_list else 'N/A'}")
        
    # ë¦¬ìŠ¤íŠ¸ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜ (ëª¨ë“  FP/Descê°€ ì´ì œ target_listì— ì±„ì›Œì ¸ ìˆìŒ)
    all_morgan_fps_raw = np.array(calculated_morgan_fps)
    all_maccs_keys_raw = np.array(calculated_maccs_keys)
    all_apfp_raw = np.array(calculated_apfp) # ì´ë¯¸ standardize_fingerprintsë¥¼ í†µí•´ í†µì¼ë¨
    all_tfp_raw = np.array(calculated_tfp)
    all_rdkit_descriptors_raw = np.array(calculated_rdkit_descriptors)


    print("ëª¨ë“  Fingerprint ë° RDKit Descriptors ê³„ì‚° ë˜ëŠ” ë¡œë“œ ì™„ë£Œ.")

    # ----------------------------------------------------------------------------------------------------
    # ğŸ”§ 6. í”¼ì²˜ ì „ì²˜ë¦¬ ë° ì„ íƒ (Lasso ê¸°ë°˜ ì ìš©)
    # ----------------------------------------------------------------------------------------------------
    train_df = train_df_original.copy()
    test_df = test_df_original.copy()
    submit_df = submit_df_original.copy()

    # ìŠ¤ì¼€ì¼ë§ì„ ìœ„í•´ ë°ì´í„° ë³µì‚¬ (ì›ë³¸ ë°ì´í„° ë³´ì¡´)
    current_all_morgan_fps = all_morgan_fps_raw.copy()
    current_all_apfp = all_apfp_raw.copy()
    current_all_tfp = all_tfp_raw.copy()
    current_all_rdkit_descriptors = all_rdkit_descriptors_raw.copy()


    # 6.1 Mordred íŠ¹ì„± ì „ì²˜ë¦¬ (Lasso ê¸°ë°˜ í”¼ì²˜ ì„ íƒ)
    mordred_processed = None
    if mordred_combined_df.shape[1] == 0:
        print("ê²½ê³ : Mordred ë””ìŠ¤í¬ë¦½í„°ê°€ 0ì°¨ì›ì´ë¯€ë¡œ Mordred ê´€ë ¨ ì „ì²˜ë¦¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        mordred_processed = np.empty((mordred_combined_df.shape[0], 0))
        best_mordred_feature_columns = pd.Index([]) # ë³€ìˆ˜ ì •ì˜
    else:
        print(f"Mordred: ê³ ì •ëœ {Config.mordred_dim} ì°¨ì›ìœ¼ë¡œ í”¼ì²˜ ì„ íƒ (Lasso ê¸°ë°˜)...")
        vt = VarianceThreshold(threshold=0.0)
        mordred_vt = vt.fit_transform(mordred_combined_df)
        mordred_vt_cols = mordred_combined_df.columns[vt.get_support()]

        scaler = StandardScaler()
        mordred_scaled = scaler.fit_transform(mordred_vt)

        corr_threshold = 0.95
        mordred_df_temp = pd.DataFrame(mordred_scaled, columns=mordred_vt_cols)

        if mordred_df_temp.shape[1] > 1:
            corr_matrix = mordred_df_temp.corr().abs()
            upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))
            to_drop = [column for column in upper_tri.columns if any(upper_tri[column] > corr_threshold)]
        else:
            to_drop = []

        if to_drop:
            mordred_filtered_corr_df = mordred_df_temp.drop(columns=to_drop)
            mordred_filtered_corr = mordred_filtered_corr_df.values
        else:
            mordred_filtered_corr_df = mordred_df_temp
            mordred_filtered_corr = mordred_scaled

        mordred_filtered_cols = mordred_filtered_corr_df.columns
        best_mordred_all_filtered_columns = mordred_filtered_cols

        if mordred_filtered_corr.shape[1] > 0:
            lasso_model_mordred = Lasso(alpha=Config.lasso_alpha, random_state=Config.seed)
            lasso_model_mordred.fit(mordred_filtered_corr[:len(train_df)], train_df['Inhibition'].values)
            selector_mordred = SelectFromModel(lasso_model_mordred, max_features=Config.mordred_dim, prefit=True, threshold=-np.inf)
            mordred_processed = selector_mordred.transform(mordred_filtered_corr)

            selected_indices_mordred = selector_mordred.get_support(indices=True)
            best_mordred_feature_columns = mordred_filtered_cols[selected_indices_mordred]
            best_lasso_model_mordred = lasso_model_mordred
        else:
            print("   - ê²½ê³ : Mordred ë””ìŠ¤í¬ë¦½í„°ê°€ ì—†ì–´ Lasso ê¸°ë°˜ í”¼ì²˜ ì„ íƒì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            mordred_processed = np.empty((mordred_filtered_corr.shape[0], 0))
            best_mordred_feature_columns = pd.Index([])


    print(f"Mordred ìµœì¢… ì²˜ë¦¬ëœ ë°ì´í„° ì°¨ì›: {mordred_processed.shape}")


    # 6.2 Morgan Fingerprint í”¼ì²˜ ì„ íƒ (Lasso ê¸°ë°˜ í”¼ì²˜ ì„ íƒ)
    print(f"\nMorgan Fingerprint í”¼ì²˜ ì„ íƒ (Top {Config.use_topN_morgan}ê°œ, Lasso ê¸°ë°˜)...")
    morgan_fps_processed = None
    if current_all_morgan_fps.shape[1] > 0:
        lasso_model_morgan = Lasso(alpha=Config.lasso_alpha, random_state=Config.seed)
        lasso_model_morgan.fit(current_all_morgan_fps[:len(train_df)], train_df['Inhibition'].values)
        selector_morgan = SelectFromModel(lasso_model_morgan, max_features=Config.use_topN_morgan, prefit=True, threshold=-np.inf)
        morgan_fps_processed = selector_morgan.transform(current_all_morgan_fps)

        current_morgan_feature_columns_indices = np.where(selector_morgan.get_support())[0]
        best_morgan_feature_columns = [f'MorganFP_{i}' for i in current_morgan_feature_columns_indices]
        best_lasso_model_morgan = lasso_model_morgan
    else:
        print("ê²½ê³ : Morgan Fingerprintê°€ 0ì°¨ì›ì´ë¯€ë¡œ í”¼ì²˜ ì„ íƒì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        morgan_fps_processed = np.empty((current_all_morgan_fps.shape[0], 0))
        best_morgan_feature_columns = []
    print(f"Morgan FP ìµœì¢… ì²˜ë¦¬ëœ ë°ì´í„° ì°¨ì›: {morgan_fps_processed.shape}")


    # 6.3 APFP í”¼ì²˜ ì„ íƒ (Lasso ê¸°ë°˜ í”¼ì²˜ ì„ íƒ)
    print(f"\nAPFP í”¼ì²˜ ì„ íƒ (Lasso ê¸°ë°˜)...")
    apfp_processed = None
    if current_all_apfp.shape[1] > 0:
        lasso_model_apfp = Lasso(alpha=Config.lasso_alpha, random_state=Config.seed)
        lasso_model_apfp.fit(current_all_apfp[:len(train_df)], train_df['Inhibition'].values)
        selector_apfp = SelectFromModel(lasso_model_apfp, prefit=True, threshold=-np.inf) # ëª¨ë“  í”¼ì²˜ë¥¼ í¬í•¨
        apfp_processed = selector_apfp.transform(current_all_apfp)
    else:
        print("ê²½ê³ : APFPê°€ 0ì°¨ì›ì´ë¯€ë¡œ í”¼ì²˜ ì„ íƒì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        apfp_processed = np.empty((current_all_apfp.shape[0], 0))
    print(f"APFP ìµœì¢… ì²˜ë¦¬ëœ ë°ì´í„° ì°¨ì›: {apfp_processed.shape}")


    # 6.4 TFP í”¼ì²˜ ì„ íƒ (Lasso ê¸°ë°˜ í”¼ì²˜ ì„ íƒ)
    print(f"\nTFP í”¼ì²˜ ì„ íƒ (Lasso ê¸°ë°˜)...")
    tfp_processed = None
    if current_all_tfp.shape[1] > 0:
        lasso_model_tfp = Lasso(alpha=Config.lasso_alpha, random_state=Config.seed)
        lasso_model_tfp.fit(current_all_tfp[:len(train_df)], train_df['Inhibition'].values)
        selector_tfp = SelectFromModel(lasso_model_tfp, prefit=True, threshold=-np.inf)
        tfp_processed = selector_tfp.transform(current_all_tfp)
    else:
        print("ê²½ê³ : TFPê°€ 0ì°¨ì›ì´ë¯€ë¡œ í”¼ì²˜ ì„ íƒì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        tfp_processed = np.empty((current_all_tfp.shape[0], 0))
    print(f"TFP ìµœì¢… ì²˜ë¦¬ëœ ë°ì´í„° ì°¨ì›: {tfp_processed.shape}")


    # 6.5 RDKit ê¸°ë³¸ ë””ìŠ¤í¬ë¦½í„° ì „ì²˜ë¦¬ (ìŠ¤ì¼€ì¼ë§ & Lasso ê¸°ë°˜ ì„ íƒ)
    print("\nRDKit ê¸°ë³¸ ë””ìŠ¤í¬ë¦½í„° ì „ì²˜ë¦¬ (ìŠ¤ì¼€ì¼ë§ & Lasso ê¸°ë°˜)...")
    rdkit_desc_processed = None
    if current_all_rdkit_descriptors.shape[1] > 0:
        scaler_rdkit = StandardScaler()
        rdkit_scaled = scaler_rdkit.fit_transform(current_all_rdkit_descriptors)

        lasso_model_rdkit = Lasso(alpha=Config.lasso_alpha, random_state=Config.seed)
        lasso_model_rdkit.fit(rdkit_scaled[:len(train_df)], train_df['Inhibition'].values)
        selector_rdkit = SelectFromModel(lasso_model_rdkit, prefit=True, threshold=-np.inf) # ëª¨ë“  í”¼ì²˜ë¥¼ í¬í•¨
        rdkit_desc_processed = selector_rdkit.transform(rdkit_scaled)
    else:
        print("ê²½ê³ : RDKit ê¸°ë³¸ ë””ìŠ¤í¬ë¦½í„°ê°€ 0ì°¨ì›ì´ë¯€ë¡œ ì „ì²˜ë¦¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        rdkit_desc_processed = np.empty((current_all_rdkit_descriptors.shape[0], 0))
    print(f"RDKit ë””ìŠ¤í¬ë¦½í„° ìµœì¢… ì²˜ë¦¬ëœ ë°ì´í„° ì°¨ì›: {rdkit_desc_processed.shape}")


    # ----------------------------------------------------------------------------------------------------
    # ğŸ”§ 6.6 ìµœì¢… ê¸€ë¡œë²Œ í”¼ì²˜ ê²°í•©
    # ----------------------------------------------------------------------------------------------------
    print("\nìµœì¢… ê¸€ë¡œë²Œ í”¼ì²˜ ê²°í•©...")
    global_features_combined = np.hstack([
        all_maccs_keys_raw,
        morgan_fps_processed,
        mordred_processed,
        apfp_processed, # ì´ì œ ì°¨ì›ì´ í†µì¼ë˜ê³  ìºì‹±ë¨
        tfp_processed, # ì´ì œ ìºì‹±ë¨
        rdkit_desc_processed # ì´ì œ ìºì‹±ë¨
    ])

    Config.global_feat_dim = global_features_combined.shape[1]
    print(f"ì „ì²´ ë°ì´í„°ì— ëŒ€í•œ Global Feature ìµœì¢… ì°¨ì›: {global_features_combined.shape}")
    print(f"GNN ëª¨ë¸ì˜ global_feat_dim: {Config.global_feat_dim}")


    # ----------------------------------------------------------------------------------------------------
    # ğŸ”§ 6.7 ì´ìƒì¹˜(Outlier) ì²˜ë¦¬ (í›ˆë ¨ ë°ì´í„°ì—ë§Œ ì ìš©)
    # ----------------------------------------------------------------------------------------------------
    if Config.remove_outliers:
        print(f"\nì´ìƒì¹˜ ì²˜ë¦¬ ì‹œì‘ (IsolationForest, contamination={Config.outlier_contamination})...")
        train_global_features = global_features_combined[:len(train_df)]

        iso_forest = IsolationForest(n_estimators=100, contamination=Config.outlier_contamination, random_state=Config.seed, n_jobs=-1)
        outlier_preds = iso_forest.fit_predict(train_global_features)
        is_inlier = outlier_preds == 1

        original_train_len = len(train_df)
        train_df = train_df[is_inlier].reset_index(drop=True)
        global_features_train_filtered = train_global_features[is_inlier]

        print(f"   - ì›ë³¸ í›ˆë ¨ ë°ì´í„° ê°œìˆ˜: {original_train_len}")
        print(f"   - ì œê±°ëœ ì´ìƒì¹˜ ê°œìˆ˜: {original_train_len - len(train_df)}")
        print(f"   - ì´ìƒì¹˜ ì œê±° í›„ í›ˆë ¨ ë°ì´í„° ê°œìˆ˜: {len(train_df)}")
    else:
        global_features_train_filtered = global_features_combined[:len(train_df)]

    global_feat_train = global_features_train_filtered
    global_feat_test = global_features_combined[len(train_df_original) : len(train_df_original) + len(test_df_original)]
    global_feat_submit = global_features_combined[len(train_df_original) + len(test_df_original) : ]


    # ----------------------------------------------------------------------------------------------------
    # ğŸ”§ 7. ê·¸ë˜í”„ ë°ì´í„°ì…‹ ìƒì„± ë° ë¡œë” ì¤€ë¹„
    # ----------------------------------------------------------------------------------------------------
    print("\nê·¸ë˜í”„ ë°ì´í„°ì…‹ ìƒì„± ì¤‘...")

    train_data_list = []
    for i, smiles in tqdm(enumerate(train_df['Canonical_Smiles'].tolist()), total=len(train_df), desc="Train Graph Data"):
        mol = Chem.MolFromSmiles(smiles)
        if mol:
            data = mol_to_graph_data(mol, global_feat_train[i], y=train_df['Inhibition'].iloc[i])
            train_data_list.append(data)
        else:
            print(f"ê²½ê³ : í›ˆë ¨ ë°ì´í„° SMILES {smiles} (index {i}) ì²˜ë¦¬ ì‹¤íŒ¨. í•´ë‹¹ ë°ì´í„° ìŠ¤í‚µ.")

    test_data_list = []
    for i, smiles in tqdm(enumerate(test_df['Canonical_Smiles'].tolist()), total=len(test_df), desc="Test Graph Data"):
        mol = Chem.MolFromSmiles(smiles)
        if mol:
            data = mol_to_graph_data(mol, global_feat_test[i])
            test_data_list.append(data)
        else:
            print(f"ê²½ê³ : í…ŒìŠ¤íŠ¸ ë°ì´í„° SMILES {smiles} (index {i}) ì²˜ë¦¬ ì‹¤íŒ¨. í•´ë‹¹ ë°ì´í„° ìŠ¤í‚µ.")

    submit_data_list = []
    for i, smiles in tqdm(enumerate(test_df['Canonical_Smiles'].tolist()), total=len(test_df), desc="Submit Graph Data"):
        mol = Chem.MolFromSmiles(smiles)
        if mol:
            data = mol_to_graph_data(mol, global_feat_submit[i])
            submit_data_list.append(data)
        else:
            print(f"ê²½ê³ : ì œì¶œ ë°ì´í„° SMILES {smiles} (index {i}) ì²˜ë¦¬ ì‹¤íŒ¨. í•´ë‹¹ ë°ì´í„° ìŠ¤í‚µ.")
    print("ê·¸ë˜í”„ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ. ëª¨ë¸ í›ˆë ¨ ì¤€ë¹„ ì¤‘...")


    # ----------------------------------------------------------------------------------------------------
    # ğŸ”§ 8. ëª¨ë¸ í›ˆë ¨ (K-Fold êµì°¨ ê²€ì¦)
    #-----------------------------------------------------------------------------------------------------
    kf = KFold(n_splits=Config.k_splits, shuffle=True, random_state=Config.seed)
    oof_preds = np.zeros(len(train_data_list))
    final_test_preds = []
    final_submit_preds = []

    print(f"\nK-Fold êµì°¨ ê²€ì¦ ì‹œì‘ (ì´ {Config.k_splits}ê°œ í´ë“œ)...")

    for fold, (train_idx, val_idx) in enumerate(kf.split(train_data_list)):
        print(f"\n--- Fold {fold+1}/{Config.k_splits} í›ˆë ¨ ì‹œì‘ ---")

        train_subset = [train_data_list[i] for i in train_idx]
        val_subset = [train_data_list[i] for i in val_idx]

        train_loader = DataLoader(train_subset, batch_size=Config.batch_size, shuffle=True)
        val_loader = DataLoader(val_subset, batch_size=Config.batch_size, shuffle=False)
        test_loader = DataLoader(test_data_list, batch_size=Config.batch_size, shuffle=False)
        submit_loader = DataLoader(submit_data_list, batch_size=Config.batch_size, shuffle=False)

        model = GATv2WithGlobal(
            node_feat_dim=Config.node_feat_dim,
            global_feat_dim=Config.global_feat_dim,
            hidden_dim=Config.use_topN_morgan,
            out_dim=1,
            num_heads=4,
            dropout_rate=0.2
        ).to(device)

        optimizer = torch.optim.Adam(model.parameters(), lr=Config.lr)
        criterion = torch.nn.MSELoss()
        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=Config.lr_patience, verbose=True)

        best_score_fold = -float('inf')
        counter = 0

        for epoch in range(1, Config.epochs + 1):
            model.train()
            train_loss = 0
            for batch in train_loader:
                batch = batch.to(device)
                optimizer.zero_grad()
                out = model(batch)
                loss = criterion(out, batch.y.view(-1))
                loss.backward()
                optimizer.step()
                train_loss += loss.item() * batch.num_graphs

            model.eval()
            preds, trues = [], []
            val_loss = 0
            with torch.no_grad():
                for batch in val_loader:
                    batch = batch.to(device)
                    out = model(batch)
                    loss = criterion(out, batch.y.view(-1))
                    val_loss += loss.item() * batch.num_graphs
                    preds.append(out.cpu().numpy())
                    trues.append(batch.y.view(-1).cpu().numpy())
            preds, trues = np.concatenate(preds), np.concatenate(trues)

            for i, val_idx_single in enumerate(val_idx):
                oof_preds[val_idx_single] = preds[i]


            rmse = np.sqrt(mean_squared_error(trues, preds))
            corr = pearsonr(trues, preds)[0]
            y_range = trues.max() - trues.min()
            normalized_rmse = rmse / y_range if y_range > 0 else 0
            score = 0.5 * (1 - min(normalized_rmse, 1)) + 0.5 * np.clip(corr, 0, 1)

            print(f"[Fold {fold+1} Epoch {epoch}] Train Loss: {train_loss/len(train_subset):.4f}, Val Loss: {val_loss/len(val_subset):.4f}, RMSE: {rmse:.4f}, Corr: {corr:.4f}, Score: {score:.4f}")

            scheduler.step(val_loss/len(val_subset))

            if score > best_score_fold:
                best_score_fold = score
                counter = 0
                torch.save(model.state_dict(), f'./_save/gnn_model_fold_{fold+1}.pt')
            else:
                counter += 1
                if counter >= Config.patience:
                    print(f"EarlyStopping at Fold {fold+1} Epoch {epoch}")
                    break

        print(f"--- Fold {fold+1} í›ˆë ¨ ì™„ë£Œ. Best Score: {best_score_fold:.4f} ---")

        torch_model_path = f'./_save/gnn_model_fold_{fold+1}.pt'
        if os.path.exists(torch_model_path):
            model.load_state_dict(torch.load(torch_model_path))
        else:
            print(f"ê²½ê³ : {torch_model_path} ëª¨ë¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šì•„ í•´ë‹¹ í´ë“œì˜ ì˜ˆì¸¡ì„ ê±´ë„ˆëœ€.")
            continue

        model.eval()

        fold_test_preds = []
        with torch.no_grad():
            for batch in test_loader:
                batch = batch.to(device)
                fold_test_preds.append(model(batch).cpu().numpy())
        final_test_preds.append(np.concatenate(fold_test_preds))

        fold_submit_preds = []
        with torch.no_grad():
            for batch in submit_loader:
                batch = batch.to(device)
                fold_submit_preds.append(model(batch).cpu().numpy())
        final_submit_preds.append(np.concatenate(fold_submit_preds))

    oof_rmse = np.sqrt(mean_squared_error(train_df['Inhibition'].values, oof_preds))
    oof_corr = pearsonr(train_df['Inhibition'].values, oof_preds)[0]
    oof_y_range = train_df['Inhibition'].values.max() - train_df['Inhibition'].values.min()
    oof_normalized_rmse = oof_rmse / oof_y_range if oof_y_range > 0 else 0
    oof_score = 0.5 * (1 - min(oof_normalized_rmse, 1)) + 0.5 * np.clip(oof_corr, 0, 1)

    print(f"\n========================================================")
    print(f"K-Fold ì „ì²´ OOF ê²°ê³¼ - RMSE: {oof_rmse:.4f}, Corr: {oof_corr:.4f}, Score: {oof_score:.4f}")
    print("========================================================\n")


    # ----------------------------------------------------------------------------------------------------
    # ğŸ”§ 9. í”¼ì²˜ ì¤‘ìš”ë„ ì‹œê°í™” (Morgan FPë§Œ)
    # ----------------------------------------------------------------------------------------------------
    if best_lasso_model_morgan is not None and best_morgan_feature_columns is not None:
        print(f"\nMorgan FP í”¼ì²˜ ì¤‘ìš”ë„ ì‹œê°í™” ì‹œì‘ (Lasso Alpha: {Config.lasso_alpha})...")

        all_morgan_fp_cols = [f'MorganFP_{i}' for i in range(Config.morgan_dim)]
        feature_coefs_full = pd.Series(best_lasso_model_morgan.coef_, index=all_morgan_fp_cols)
        
        selected_feature_coefs = feature_coefs_full[best_morgan_feature_columns].abs().sort_values(ascending=False)

        top_n = min(20, len(selected_feature_coefs))

        if top_n > 0:
            plt.figure(figsize=(12, max(6, top_n * 0.4)))
            sns.barplot(x=selected_feature_coefs.head(top_n).values,
                        y=selected_feature_coefs.head(top_n).index)
            plt.title(f'Morgan FP ìƒìœ„ {top_n}ê°œ í”¼ì²˜ ì¤‘ìš”ë„ (Lasso ì ˆëŒ€ ê³„ìˆ˜)')
            plt.xlabel('í”¼ì²˜ ì¤‘ìš”ë„ (ì ˆëŒ€ ê³„ìˆ˜)')
            plt.ylabel('Morgan Fingerprint ë¹„íŠ¸')
            plt.tight_layout()
            plt.savefig('./_save/morgan_lasso_feature_importance.png')
            plt.show()
            print(f"Morgan FP í”¼ì²˜ ì¤‘ìš”ë„ ì‹œê°í™”ê°€ './_save/morgan_lasso_feature_importance.png'ì— ì €ì¥ë¨.")
        else:
            print("ì„ íƒëœ Morgan FP í”¼ì²˜ê°€ ì—†ê±°ë‚˜ ì¤‘ìš”ë„ë¥¼ ì‹œê°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        print("Morgan FP í”¼ì²˜ ì¤‘ìš”ë„ ì‹œê°í™”ë¥¼ ìœ„í•œ ì •ë³´ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. (Lasso ëª¨ë¸ ë˜ëŠ” ì»¬ëŸ¼ëª… ì—†ìŒ)")

    # ----------------------------------------------------------------------------------------------------
    # 10. ìµœì¢… ì œì¶œ íŒŒì¼ ìƒì„± (K-Fold ì˜ˆì¸¡ í‰ê· )
    # ----------------------------------------------------------------------------------------------------
    print("\nìµœì¢… ì œì¶œ íŒŒì¼ ìƒì„± ì¤‘...")
    if final_test_preds and final_submit_preds:
        avg_test_preds = np.mean(final_test_preds, axis=0)
        avg_submit_preds = np.mean(final_submit_preds, axis=0)

        submit_df_original['Inhibition'] = avg_submit_preds
        
        submission_filename = f'./_save/submission_combined_features_LassoAlpha_{Config.lasso_alpha}.csv'
        submit_df_original.to_csv(submission_filename, index=False)
        print(f"ìµœì¢… ì œì¶œ íŒŒì¼ì´ '{submission_filename}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("ìµœì¢… ì˜ˆì¸¡ê°’ì´ ì—†ì–´ ì œì¶œ íŒŒì¼ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (K-Fold í›ˆë ¨ì´ ì‹¤íŒ¨í–ˆê±°ë‚˜ ë°ì´í„° ë¬¸ì œ)")

    print("\nëª¨ë“  ì‘ì—… ì™„ë£Œ.")