# https://www.kaggle.com/competitions/santander-customer-transaction-prediction


import numpy as np                                           # í›ˆë ¨ì— íŠ¹í™”ë¨.
import pandas as pd                                          # ë°ì´í„°ë¶„ì„ì„ í•  ë•Œ ì „ì²˜ë¦¬, ì •ì œì—ì„œ ìœ ëª…í•¨.
from keras.models import Sequential
from keras.layers import Dense, Dropout, BatchNormalization
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, f1_score
from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler, RobustScaler
from keras.callbacks import EarlyStopping, ModelCheckpoint

#1. ë°ì´í„°
path = './_data/kaggle/santander/'  
train_csv = pd.read_csv(path + 'train.csv', index_col=0)
test_csv = pd.read_csv(path + 'test.csv', index_col=0) 
sample_submission_csv = pd.read_csv(path + 'sample_submission.csv')

print(sample_submission_csv) #[200000 rows x 2 columns]

print(train_csv)                        # [200000 rows x 201 columns]
print(train_csv.columns)                # Index(['target', 'var_0', 'var_1', 'var_2', 'var_3', 'var_4', 'var_5', 'var_6',
                                        #    'var_7', 'var_8',
                                        #    ...
                                        #    'var_190', 'var_191', 'var_192', 'var_193', 'var_194', 'var_195',
                                        #    'var_196', 'var_197', 'var_198', 'var_199'],
                                        #   dtype='object', length=201)
                                        # dtype='object')        
                                                             
print(test_csv)                         # [200000 rows x 200 columns]
print(test_csv.columns)                 # Index(['var_0', 'var_1', 'var_2', 'var_3', 'var_4', 'var_5', 'var_6', 'var_7',
                                        #        'var_8', 'var_9',
                                        #        ...
                                        #        'var_190', 'var_191', 'var_192', 'var_193', 'var_194', 'var_195',
                                        #        'var_196', 'var_197', 'var_198', 'var_199'],
                                        # dtype='object', length=200)                       
print(sample_submission_csv)             # [200000 rows x 2 columns]
print(sample_submission_csv.columns)     # Index(['datetime','count'], dtype='object') 


# ê²°ì¸¡ì¹˜ í™•ì¸
    
print(train_csv.info())                 
print(train_csv.isnull().sum())         #ê²°ì¸¡ì¹˜ ì—†ìŒ
print(test_csv.isna().sum())            #ê²°ì¸¡ì¹˜ ì—†ìŒ

print(train_csv.describe())             


# #################### x,y ë°ì´í„°ë¥¼ ë¶„ë¦¬í•œë‹¤ ##########################
print('###############################################################################')
x = train_csv.drop(['ID','target'], axis=1) # target, ID columnë§Œ ë¹¼ê² ë‹¤.
print(x)                               # [200000 rows x 200 columns]
                       
y = train_csv['target']                # target columnë§Œ ë¹¼ì„œ yì— ë„£ê² ë‹¤.
print(y)  
print(y.shape)                         # (200000,)

# exit()

x_train, x_test, y_train, y_test = train_test_split(
    x,y,
    test_size=0.2,
    random_state=74, # validation_splitë¡œë„ ë°”ë€Œì§€ì•ŠëŠ”ë‹¤ë©´ ë°”ê¾¸ì
    stratify=y
    )

# scaler=MinMaxScaler()
# scaler=StandardScaler()
# scaler=MaxAbsScaler()
# scaler=RobustScaler()
# x_train = scaler.fit_transform(x_train)
# x_test = scaler.transform(x_test)

# #2. ëª¨ë¸êµ¬ì„±

model = Sequential()
model.add(Dense(128, input_dim=x.shape[1], activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(0.1))  
model.add(Dense(64,activation='relu'))
model.add(Dropout(0.1))  
model.add(Dense(64,activation='relu'))
model.add(Dropout(0.1))  
model.add(Dense(64,activation='relu'))
model.add(Dropout(0.2))  
model.add(Dense(32,activation='relu'))
model.add(Dropout(0.2))  
model.add(Dense(1, activation='sigmoid'))

path='./_save/keras30/Scaler12_kaggle_santander/'
model.save_weights(path+'keras30_05_kaggle_santander_weights.h5')

#3. ì»´íŒŒì¼, í›ˆë ¨
model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])

es = EarlyStopping(                  
    monitor='val_loss',
    mode = 'min',                      
    patience=30,                       
    restore_best_weights=True,        
) 

path='./_save/keras30/Scaler12_kaggle_santander/'
mcp=ModelCheckpoint(
    monitor='val_loss',
    mode='auto',
    save_best_only=True,    
    filepath=path+'keras30_05_kaggle_santander.hdf5'
    )

hist = model.fit(x,y, epochs=300, batch_size=128,
          verbose =2,
          validation_split=0.2,
          callbacks=[es, mcp],
          )

path='./_save/keras30/Scaler12_kaggle_santander/'
model.save(path+'keras30_05_kaggle_santander.h5')

print('========================hist============================')
print(hist) # keras.callbacks.History object at 0x000002AE4E644220> ìœ¼ë¡œ ë‚˜ì˜¤ëŠ”ë° ì œëŒ€ë¡œ ë³¼ë ¤ë©´ 
print('========================hist.history============================')
print(hist.history)  # ì¤‘ê´„í˜¸ì˜ ë“±ì¥ : í‚¤(loss, val_loss) : ë²¨ë¥˜(ìˆ«ì) í˜•íƒœë¡œ ì•ˆì— ë„£ì–´ë‘”ë‹¤ // loss, val loss ì˜ ê°¯ìˆ˜ëŠ” epochs ê°’ê³¼ ë˜‘ê°™ìŒ
                     # lossë“¤ì˜ ì—­ì‚¬ 
                     # ê·¸ë˜í”„ì˜ ì‹œê°í™”ê°€ ê°€ëŠ¥í•˜ë‹¤ ì ë“¤ì˜ ê°’ì´ ìˆê¸° ë–„ë¬¸ì—

print('========================hist.historyì—ì„œ lossë§Œ ë”°ë¡œë³´ê³ ì‹¶ë‹¤============================')
print(hist.history['loss'])   # dictionaryì˜ í‚¤ê°’ë§Œ ì ì–´ì£¼ë©´ëœë‹¤                     
       
print('========================hist.historyì—ì„œ val_lossë§Œ ë”°ë¡œë³´ê³ ì‹¶ë‹¤============================')
print(hist.history['val_loss'])   # dictionaryì˜ í‚¤ê°’ë§Œ ì ì–´ì£¼ë©´ëœë‹¤

#4. í‰ê°€, ì˜ˆì¸¡
loss = model.evaluate(x_test,y_test)
results = model.predict(x_test)

best_thresh = 0.5
best_f1 = 0

for thresh in np.arange(0.1, 0.9, 0.01):
    pred_bin = (results > thresh).astype(int).reshape(-1)
    f1 = f1_score(y_test, pred_bin)
    if f1 > best_f1:
        best_f1 = f1
        best_thresh = thresh

print(f"Best threshold: {best_thresh}, Best F1 Score: {best_f1:.4f}")
print("loss : ", loss)

# submission.csvì— test_csvì˜ ì˜ˆì¸¡ê°’ ë„£ê¸°
y_submit = model.predict(test_csv)
y_submit = np.round(y_submit) # train ë°ì´í„°ì˜ shapeì™€ ë™ì¼í•œ ì»¬ëŸ¼ì„ í™•ì¸í•˜ê³  ë„£ì
#print(y_submit)                        # x_train.shape: (N, 9)
#print(y_submit.shape) # (715, 1)

############## submission.csv íŒŒì¼ ë§Œë“¤ê¸°// count ì»¬ëŸ¼ê°’ë§Œ ë„£ì–´ì£¼ê¸° ####################
sample_submission_csv['target'] = y_submit
#print(samplesubmission_csv)
# print(submission_csv)

######################## csvíŒŒì¼ ë§Œë“¤ê¸° ######################
path='./_save/keras30/Scaler12_kaggle_santander/'
sample_submission_csv.to_csv(path + 'sample_submission_csv_0608_1140.csv', index=False) # csv ë§Œë“¤ê¸°.
print("\nğŸ“ 'sample_submission_csv' ì €ì¥ ì™„ë£Œ!")

import matplotlib.pyplot as plt        # ë§·í”Œë¡œë¦½
import matplotlib.font_manager as fm
import matplotlib as mpl

font_path = "C:/Windows/Fonts/malgun.ttf"  # ë˜ëŠ” ë‹¤ë¥¸ í•œê¸€ í°íŠ¸ ê²½ë¡œ
font_name = fm.FontProperties(fname=font_path).get_name()
mpl.rc('font', family=font_name)
mpl.rcParams['axes.unicode_minus'] = False

plt.figure(figsize=(9,6))         # 9X6ì‚¬ì´ì¦ˆë¡œ ë§Œë“¤ì–´ì¤˜
plt.plot(hist.history['loss'], c='red', label = 'loss')                        # ì„ ê·¸ë¦¬ëŠ”ê²Œ plot //  lossì˜ ê·¸ë¦¼ì„ ê·¸ë¦¬ê³ ì‹¶ì–´ // yì¶•ì€ loss xì¶•ì€ epochs í›ˆë ¨ëŸ‰ì— ë”°ë¥¸ lossê°’ ì‚°ì¶œ  
                                                                               # ë¦¬ìŠ¤íŠ¸ëŠ” ìˆœì„œëŒ€ë¡œ ê°€ê¸°ë•Œë¬¸ì— xë¥¼ë”°ë¡œ ëª…ì‹œì•ˆí•´ë„ëœë‹¤. // yê°’ë§Œ ë„£ìœ¼ë©´ ì‹œê°„ìˆœìœ¼ë¡œ ê·¸ë¦¼ì„ ê·¸ë¦¼
plt.plot(hist.history['val_loss'], c='blue', label = 'val_loss')               
plt.title('santander Loss')
plt.xlabel('epochs')
plt.ylabel('loss')
plt.legend(loc='upper right')  # ìš°ì¸¡ ìƒë‹¨ì— label í‘œì‹œ
plt.grid()                     # ê²©ìí‘œì‹œ
plt.show()

"""
loss :  [0.22916652262210846, 0.9146749973297119]
r2 :  0.2684763699467141
RMSE :  0.25715667068133685
"""